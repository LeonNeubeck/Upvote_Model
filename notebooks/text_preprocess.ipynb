{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../raw_data/100k_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../raw_data/SEND_150k_data.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "# data = data.dropna()\n",
    "df = data.dropna().sample(30000,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72359</th>\n",
       "      <td>This is Picard. His gotcha day was February 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117238</th>\n",
       "      <td>Hound Nap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74310</th>\n",
       "      <td>When is breakfast?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110206</th>\n",
       "      <td>Finally figured out where the socks disappear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49964</th>\n",
       "      <td>Walter Post-Surgery with his dinosaur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105794</th>\n",
       "      <td>First look for my lovely john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40869</th>\n",
       "      <td>They Say Sleeping Is Good For You!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92190</th>\n",
       "      <td>Just chillin after a long day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57167</th>\n",
       "      <td>Hail to the king baby ğŸ‘‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109746</th>\n",
       "      <td>Our Akitan Family everyday - day 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54282</th>\n",
       "      <td>My good boy, ringing in the new year with his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49350</th>\n",
       "      <td>I was strolling through Turin (IT) when I saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>From eating dirt to majestic in three seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80003</th>\n",
       "      <td>I lost Maki yesterday to blood cancer. I know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132276</th>\n",
       "      <td>My dog is cooler than yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70254</th>\n",
       "      <td>My parents last Borzoi and my first Labrador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129993</th>\n",
       "      <td>TODAY WE FOUND A LONG STICK AND ITS FANTASTIC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128627</th>\n",
       "      <td>Such a goofball!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85970</th>\n",
       "      <td>happy holidays from my doggo to yours! :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108056</th>\n",
       "      <td>The goodest boi probably wished for new parent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title\n",
       "72359   This is Picard. His gotcha day was February 11...\n",
       "117238                                          Hound Nap\n",
       "74310                                 When is breakfast?!\n",
       "110206  Finally figured out where the socks disappear ...\n",
       "49964               Walter Post-Surgery with his dinosaur\n",
       "105794                      First look for my lovely john\n",
       "40869                  They Say Sleeping Is Good For You!\n",
       "92190                       Just chillin after a long day\n",
       "57167                             Hail to the king baby ğŸ‘‘\n",
       "109746                 Our Akitan Family everyday - day 1\n",
       "54282   My good boy, ringing in the new year with his ...\n",
       "49350   I was strolling through Turin (IT) when I saw ...\n",
       "4870        From eating dirt to majestic in three seconds\n",
       "80003   I lost Maki yesterday to blood cancer. I know ...\n",
       "132276                        My dog is cooler than yours\n",
       "70254        My parents last Borzoi and my first Labrador\n",
       "129993     TODAY WE FOUND A LONG STICK AND ITS FANTASTIC.\n",
       "128627                                   Such a goofball!\n",
       "85970           happy holidays from my doggo to yours! :)\n",
       "108056  The goodest boi probably wished for new parent..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_len(text):\n",
    "    text = text.split(' ')\n",
    "    length = len(text)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_len']=df['title'].apply(count_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_len']=data['title'].apply(count_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.573566666666666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_len'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.588895179660035"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title_len'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emot in /Users/wanghin/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages (3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emot # package to process emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import string\n",
    "from emot.emo_unicode import UNICODE_EMOJI\n",
    "import nltk\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Demojize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# function demojize(self, text):\n",
    "#    emoji.demojize(text)\n",
    "\n",
    "# function word2vec(self, text):\n",
    "#    new_text = self.demojize(text)\n",
    "#    my_vect = Word2Vec(new_test)\n",
    "#    return my_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def demojize(text):\n",
    "    clean_text = emoji.demojize(text)\n",
    "    clean_text = clean_text.replace(':', '')\n",
    "    clean_text = clean_text.replace('_', ' ')\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# demojize('Python is ğŸ‘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df['title'] = df.title.apply(demojize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Base Model, I decide to not consider the impact of special Punctuation like '?' and '!'\n",
    "(strip + lowercase + numbers + punctuation/symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Contraction Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CONTRACTION_MAP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rd/q2lzfdss4b167026m7l6h8pm0000gn/T/ipykernel_88515/1922275859.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# expand_contractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mexpand_contractions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONTRACTION_MAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n\u001b[1;32m      5\u001b[0m                                       flags=re.IGNORECASE|re.DOTALL)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CONTRACTION_MAP' is not defined"
     ]
    }
   ],
   "source": [
    "# expand_contractions\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['basic_cleaning'] = df.title.apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_punc = string.punctuation\n",
    "my_punc += 'â€”'\n",
    "my_punc += 'â€œâ€â€™'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    for punctuation in my_punc:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'basic_cleaning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rd/q2lzfdss4b167026m7l6h8pm0000gn/T/ipykernel_88515/2813984758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'basic_cleaning'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_cleaning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_cleaning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5573\u001b[0m         ):\n\u001b[1;32m   5574\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'basic_cleaning'"
     ]
    }
   ],
   "source": [
    "df['basic_cleaning'] = df.basic_cleaning.apply(basic_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Emoji to Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ğŸ¥‡': ':1st_place_medal:',\n",
       " 'ğŸ¥ˆ': ':2nd_place_medal:',\n",
       " 'ğŸ¥‰': ':3rd_place_medal:',\n",
       " 'ğŸ†': ':AB_button_(blood_type):',\n",
       " 'ğŸ§': ':ATM_sign:',\n",
       " 'ğŸ…°': ':A_button_(blood_type):',\n",
       " 'ğŸ‡¦ğŸ‡«': ':Afghanistan:',\n",
       " 'ğŸ‡¦ğŸ‡±': ':Albania:',\n",
       " 'ğŸ‡©ğŸ‡¿': ':Algeria:',\n",
       " 'ğŸ‡¦ğŸ‡¸': ':American_Samoa:',\n",
       " 'ğŸ‡¦ğŸ‡©': ':Andorra:',\n",
       " 'ğŸ‡¦ğŸ‡´': ':Angola:',\n",
       " 'ğŸ‡¦ğŸ‡®': ':Anguilla:',\n",
       " 'ğŸ‡¦ğŸ‡¶': ':Antarctica:',\n",
       " 'ğŸ‡¦ğŸ‡¬': ':Antigua_&_Barbuda:',\n",
       " 'â™’': ':Aquarius:',\n",
       " 'ğŸ‡¦ğŸ‡·': ':Argentina:',\n",
       " 'â™ˆ': ':Aries:',\n",
       " 'ğŸ‡¦ğŸ‡²': ':Armenia:',\n",
       " 'ğŸ‡¦ğŸ‡¼': ':Aruba:',\n",
       " 'ğŸ‡¦ğŸ‡¨': ':Ascension_Island:',\n",
       " 'ğŸ‡¦ğŸ‡º': ':Australia:',\n",
       " 'ğŸ‡¦ğŸ‡¹': ':Austria:',\n",
       " 'ğŸ‡¦ğŸ‡¿': ':Azerbaijan:',\n",
       " 'ğŸ”™': ':BACK_arrow:',\n",
       " 'ğŸ…±': ':B_button_(blood_type):',\n",
       " 'ğŸ‡§ğŸ‡¸': ':Bahamas:',\n",
       " 'ğŸ‡§ğŸ‡­': ':Bahrain:',\n",
       " 'ğŸ‡§ğŸ‡©': ':Bangladesh:',\n",
       " 'ğŸ‡§ğŸ‡§': ':Barbados:',\n",
       " 'ğŸ‡§ğŸ‡¾': ':Belarus:',\n",
       " 'ğŸ‡§ğŸ‡ª': ':Belgium:',\n",
       " 'ğŸ‡§ğŸ‡¿': ':Belize:',\n",
       " 'ğŸ‡§ğŸ‡¯': ':Benin:',\n",
       " 'ğŸ‡§ğŸ‡²': ':Bermuda:',\n",
       " 'ğŸ‡§ğŸ‡¹': ':Bhutan:',\n",
       " 'ğŸ‡§ğŸ‡´': ':Bolivia:',\n",
       " 'ğŸ‡§ğŸ‡¦': ':Bosnia_&_Herzegovina:',\n",
       " 'ğŸ‡§ğŸ‡¼': ':Botswana:',\n",
       " 'ğŸ‡§ğŸ‡»': ':Bouvet_Island:',\n",
       " 'ğŸ‡§ğŸ‡·': ':Brazil:',\n",
       " 'ğŸ‡®ğŸ‡´': ':British_Indian_Ocean_Territory:',\n",
       " 'ğŸ‡»ğŸ‡¬': ':British_Virgin_Islands:',\n",
       " 'ğŸ‡§ğŸ‡³': ':Brunei:',\n",
       " 'ğŸ‡§ğŸ‡¬': ':Bulgaria:',\n",
       " 'ğŸ‡§ğŸ‡«': ':Burkina_Faso:',\n",
       " 'ğŸ‡§ğŸ‡®': ':Burundi:',\n",
       " 'ğŸ†‘': ':CL_button:',\n",
       " 'ğŸ†’': ':COOL_button:',\n",
       " 'ğŸ‡°ğŸ‡­': ':Cambodia:',\n",
       " 'ğŸ‡¨ğŸ‡²': ':Cameroon:',\n",
       " 'ğŸ‡¨ğŸ‡¦': ':Canada:',\n",
       " 'ğŸ‡®ğŸ‡¨': ':Canary_Islands:',\n",
       " 'â™‹': ':Cancer:',\n",
       " 'ğŸ‡¨ğŸ‡»': ':Cape_Verde:',\n",
       " 'â™‘': ':Capricorn:',\n",
       " 'ğŸ‡§ğŸ‡¶': ':Caribbean_Netherlands:',\n",
       " 'ğŸ‡°ğŸ‡¾': ':Cayman_Islands:',\n",
       " 'ğŸ‡¨ğŸ‡«': ':Central_African_Republic:',\n",
       " 'ğŸ‡ªğŸ‡¦': ':Ceuta_&_Melilla:',\n",
       " 'ğŸ‡¹ğŸ‡©': ':Chad:',\n",
       " 'ğŸ‡¨ğŸ‡±': ':Chile:',\n",
       " 'ğŸ‡¨ğŸ‡³': ':China:',\n",
       " 'ğŸ‡¨ğŸ‡½': ':Christmas_Island:',\n",
       " 'ğŸ„': ':Christmas_tree:',\n",
       " 'ğŸ‡¨ğŸ‡µ': ':Clipperton_Island:',\n",
       " 'ğŸ‡¨ğŸ‡¨': ':Cocos_(Keeling)_Islands:',\n",
       " 'ğŸ‡¨ğŸ‡´': ':Colombia:',\n",
       " 'ğŸ‡°ğŸ‡²': ':Comoros:',\n",
       " 'ğŸ‡¨ğŸ‡¬': ':Congo_-_Brazzaville:',\n",
       " 'ğŸ‡¨ğŸ‡©': ':Congo_-_Kinshasa:',\n",
       " 'ğŸ‡¨ğŸ‡°': ':Cook_Islands:',\n",
       " 'ğŸ‡¨ğŸ‡·': ':Costa_Rica:',\n",
       " 'ğŸ‡­ğŸ‡·': ':Croatia:',\n",
       " 'ğŸ‡¨ğŸ‡º': ':Cuba:',\n",
       " 'ğŸ‡¨ğŸ‡¼': ':CuraÃ§ao:',\n",
       " 'ğŸ‡¨ğŸ‡¾': ':Cyprus:',\n",
       " 'ğŸ‡¨ğŸ‡¿': ':Czechia:',\n",
       " 'ğŸ‡¨ğŸ‡®': ':CÃ´te_dâ€™Ivoire:',\n",
       " 'ğŸ‡©ğŸ‡°': ':Denmark:',\n",
       " 'ğŸ‡©ğŸ‡¬': ':Diego_Garcia:',\n",
       " 'ğŸ‡©ğŸ‡¯': ':Djibouti:',\n",
       " 'ğŸ‡©ğŸ‡²': ':Dominica:',\n",
       " 'ğŸ‡©ğŸ‡´': ':Dominican_Republic:',\n",
       " 'ğŸ”š': ':END_arrow:',\n",
       " 'ğŸ‡ªğŸ‡¨': ':Ecuador:',\n",
       " 'ğŸ‡ªğŸ‡¬': ':Egypt:',\n",
       " 'ğŸ‡¸ğŸ‡»': ':El_Salvador:',\n",
       " 'ğŸ´\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f': ':England:',\n",
       " 'ğŸ‡¬ğŸ‡¶': ':Equatorial_Guinea:',\n",
       " 'ğŸ‡ªğŸ‡·': ':Eritrea:',\n",
       " 'ğŸ‡ªğŸ‡ª': ':Estonia:',\n",
       " 'ğŸ‡¸ğŸ‡¿': ':Eswatini:',\n",
       " 'ğŸ‡ªğŸ‡¹': ':Ethiopia:',\n",
       " 'ğŸ‡ªğŸ‡º': ':European_Union:',\n",
       " 'ğŸ†“': ':FREE_button:',\n",
       " 'ğŸ‡«ğŸ‡°': ':Falkland_Islands:',\n",
       " 'ğŸ‡«ğŸ‡´': ':Faroe_Islands:',\n",
       " 'ğŸ‡«ğŸ‡¯': ':Fiji:',\n",
       " 'ğŸ‡«ğŸ‡®': ':Finland:',\n",
       " 'ğŸ‡«ğŸ‡·': ':France:',\n",
       " 'ğŸ‡¬ğŸ‡«': ':French_Guiana:',\n",
       " 'ğŸ‡µğŸ‡«': ':French_Polynesia:',\n",
       " 'ğŸ‡¹ğŸ‡«': ':French_Southern_Territories:',\n",
       " 'ğŸ‡¬ğŸ‡¦': ':Gabon:',\n",
       " 'ğŸ‡¬ğŸ‡²': ':Gambia:',\n",
       " 'â™Š': ':Gemini:',\n",
       " 'ğŸ‡¬ğŸ‡ª': ':Georgia:',\n",
       " 'ğŸ‡©ğŸ‡ª': ':Germany:',\n",
       " 'ğŸ‡¬ğŸ‡­': ':Ghana:',\n",
       " 'ğŸ‡¬ğŸ‡®': ':Gibraltar:',\n",
       " 'ğŸ‡¬ğŸ‡·': ':Greece:',\n",
       " 'ğŸ‡¬ğŸ‡±': ':Greenland:',\n",
       " 'ğŸ‡¬ğŸ‡©': ':Grenada:',\n",
       " 'ğŸ‡¬ğŸ‡µ': ':Guadeloupe:',\n",
       " 'ğŸ‡¬ğŸ‡º': ':Guam:',\n",
       " 'ğŸ‡¬ğŸ‡¹': ':Guatemala:',\n",
       " 'ğŸ‡¬ğŸ‡¬': ':Guernsey:',\n",
       " 'ğŸ‡¬ğŸ‡³': ':Guinea:',\n",
       " 'ğŸ‡¬ğŸ‡¼': ':Guinea-Bissau:',\n",
       " 'ğŸ‡¬ğŸ‡¾': ':Guyana:',\n",
       " 'ğŸ‡­ğŸ‡¹': ':Haiti:',\n",
       " 'ğŸ‡­ğŸ‡²': ':Heard_&_McDonald_Islands:',\n",
       " 'ğŸ‡­ğŸ‡³': ':Honduras:',\n",
       " 'ğŸ‡­ğŸ‡°': ':Hong_Kong_SAR_China:',\n",
       " 'ğŸ‡­ğŸ‡º': ':Hungary:',\n",
       " 'ğŸ†”': ':ID_button:',\n",
       " 'ğŸ‡®ğŸ‡¸': ':Iceland:',\n",
       " 'ğŸ‡®ğŸ‡³': ':India:',\n",
       " 'ğŸ‡®ğŸ‡©': ':Indonesia:',\n",
       " 'ğŸ‡®ğŸ‡·': ':Iran:',\n",
       " 'ğŸ‡®ğŸ‡¶': ':Iraq:',\n",
       " 'ğŸ‡®ğŸ‡ª': ':Ireland:',\n",
       " 'ğŸ‡®ğŸ‡²': ':Isle_of_Man:',\n",
       " 'ğŸ‡®ğŸ‡±': ':Israel:',\n",
       " 'ğŸ‡®ğŸ‡¹': ':Italy:',\n",
       " 'ğŸ‡¯ğŸ‡²': ':Jamaica:',\n",
       " 'ğŸ‡¯ğŸ‡µ': ':Japan:',\n",
       " 'ğŸ‰‘': ':Japanese_acceptable_button:',\n",
       " 'ğŸˆ¸': ':Japanese_application_button:',\n",
       " 'ğŸ‰': ':Japanese_bargain_button:',\n",
       " 'ğŸ¯': ':Japanese_castle:',\n",
       " 'ãŠ—': ':Japanese_congratulations_button:',\n",
       " 'ğŸˆ¹': ':Japanese_discount_button:',\n",
       " 'ğŸ': ':Japanese_dolls:',\n",
       " 'ğŸˆš': ':Japanese_free_of_charge_button:',\n",
       " 'ğŸˆ': ':Japanese_here_button:',\n",
       " 'ğŸˆ·': ':Japanese_monthly_amount_button:',\n",
       " 'ğŸˆµ': ':Japanese_no_vacancy_button:',\n",
       " 'ğŸˆ¶': ':Japanese_not_free_of_charge_button:',\n",
       " 'ğŸˆº': ':Japanese_open_for_business_button:',\n",
       " 'ğŸˆ´': ':Japanese_passing_grade_button:',\n",
       " 'ğŸ£': ':Japanese_post_office:',\n",
       " 'ğŸˆ²': ':Japanese_prohibited_button:',\n",
       " 'ğŸˆ¯': ':Japanese_reserved_button:',\n",
       " 'ãŠ™': ':Japanese_secret_button:',\n",
       " 'ğŸˆ‚': ':Japanese_service_charge_button:',\n",
       " 'ğŸ”°': ':Japanese_symbol_for_beginner:',\n",
       " 'ğŸˆ³': ':Japanese_vacancy_button:',\n",
       " 'ğŸ‡¯ğŸ‡ª': ':Jersey:',\n",
       " 'ğŸ‡¯ğŸ‡´': ':Jordan:',\n",
       " 'ğŸ‡°ğŸ‡¿': ':Kazakhstan:',\n",
       " 'ğŸ‡°ğŸ‡ª': ':Kenya:',\n",
       " 'ğŸ‡°ğŸ‡®': ':Kiribati:',\n",
       " 'ğŸ‡½ğŸ‡°': ':Kosovo:',\n",
       " 'ğŸ‡°ğŸ‡¼': ':Kuwait:',\n",
       " 'ğŸ‡°ğŸ‡¬': ':Kyrgyzstan:',\n",
       " 'ğŸ‡±ğŸ‡¦': ':Laos:',\n",
       " 'ğŸ‡±ğŸ‡»': ':Latvia:',\n",
       " 'ğŸ‡±ğŸ‡§': ':Lebanon:',\n",
       " 'â™Œ': ':Leo:',\n",
       " 'ğŸ‡±ğŸ‡¸': ':Lesotho:',\n",
       " 'ğŸ‡±ğŸ‡·': ':Liberia:',\n",
       " 'â™': ':Libra:',\n",
       " 'ğŸ‡±ğŸ‡¾': ':Libya:',\n",
       " 'ğŸ‡±ğŸ‡®': ':Liechtenstein:',\n",
       " 'ğŸ‡±ğŸ‡¹': ':Lithuania:',\n",
       " 'ğŸ‡±ğŸ‡º': ':Luxembourg:',\n",
       " 'ğŸ‡²ğŸ‡´': ':Macao_SAR_China:',\n",
       " 'ğŸ‡²ğŸ‡¬': ':Madagascar:',\n",
       " 'ğŸ‡²ğŸ‡¼': ':Malawi:',\n",
       " 'ğŸ‡²ğŸ‡¾': ':Malaysia:',\n",
       " 'ğŸ‡²ğŸ‡»': ':Maldives:',\n",
       " 'ğŸ‡²ğŸ‡±': ':Mali:',\n",
       " 'ğŸ‡²ğŸ‡¹': ':Malta:',\n",
       " 'ğŸ‡²ğŸ‡­': ':Marshall_Islands:',\n",
       " 'ğŸ‡²ğŸ‡¶': ':Martinique:',\n",
       " 'ğŸ‡²ğŸ‡·': ':Mauritania:',\n",
       " 'ğŸ‡²ğŸ‡º': ':Mauritius:',\n",
       " 'ğŸ‡¾ğŸ‡¹': ':Mayotte:',\n",
       " 'ğŸ‡²ğŸ‡½': ':Mexico:',\n",
       " 'ğŸ‡«ğŸ‡²': ':Micronesia:',\n",
       " 'ğŸ‡²ğŸ‡©': ':Moldova:',\n",
       " 'ğŸ‡²ğŸ‡¨': ':Monaco:',\n",
       " 'ğŸ‡²ğŸ‡³': ':Mongolia:',\n",
       " 'ğŸ‡²ğŸ‡ª': ':Montenegro:',\n",
       " 'ğŸ‡²ğŸ‡¸': ':Montserrat:',\n",
       " 'ğŸ‡²ğŸ‡¦': ':Morocco:',\n",
       " 'ğŸ‡²ğŸ‡¿': ':Mozambique:',\n",
       " 'ğŸ¤¶': ':Mrs._Claus:',\n",
       " 'ğŸ¤¶ğŸ¿': ':Mrs._Claus_dark_skin_tone:',\n",
       " 'ğŸ¤¶ğŸ»': ':Mrs._Claus_light_skin_tone:',\n",
       " 'ğŸ¤¶ğŸ¾': ':Mrs._Claus_medium-dark_skin_tone:',\n",
       " 'ğŸ¤¶ğŸ¼': ':Mrs._Claus_medium-light_skin_tone:',\n",
       " 'ğŸ¤¶ğŸ½': ':Mrs._Claus_medium_skin_tone:',\n",
       " 'ğŸ‡²ğŸ‡²': ':Myanmar_(Burma):',\n",
       " 'ğŸ†•': ':NEW_button:',\n",
       " 'ğŸ†–': ':NG_button:',\n",
       " 'ğŸ‡³ğŸ‡¦': ':Namibia:',\n",
       " 'ğŸ‡³ğŸ‡·': ':Nauru:',\n",
       " 'ğŸ‡³ğŸ‡µ': ':Nepal:',\n",
       " 'ğŸ‡³ğŸ‡±': ':Netherlands:',\n",
       " 'ğŸ‡³ğŸ‡¨': ':New_Caledonia:',\n",
       " 'ğŸ‡³ğŸ‡¿': ':New_Zealand:',\n",
       " 'ğŸ‡³ğŸ‡®': ':Nicaragua:',\n",
       " 'ğŸ‡³ğŸ‡ª': ':Niger:',\n",
       " 'ğŸ‡³ğŸ‡¬': ':Nigeria:',\n",
       " 'ğŸ‡³ğŸ‡º': ':Niue:',\n",
       " 'ğŸ‡³ğŸ‡«': ':Norfolk_Island:',\n",
       " 'ğŸ‡°ğŸ‡µ': ':North_Korea:',\n",
       " 'ğŸ‡²ğŸ‡°': ':North_Macedonia:',\n",
       " 'ğŸ‡²ğŸ‡µ': ':Northern_Mariana_Islands:',\n",
       " 'ğŸ‡³ğŸ‡´': ':Norway:',\n",
       " 'ğŸ†—': ':OK_button:',\n",
       " 'ğŸ‘Œ': ':OK_hand:',\n",
       " 'ğŸ‘ŒğŸ¿': ':OK_hand_dark_skin_tone:',\n",
       " 'ğŸ‘ŒğŸ»': ':OK_hand_light_skin_tone:',\n",
       " 'ğŸ‘ŒğŸ¾': ':OK_hand_medium-dark_skin_tone:',\n",
       " 'ğŸ‘ŒğŸ¼': ':OK_hand_medium-light_skin_tone:',\n",
       " 'ğŸ‘ŒğŸ½': ':OK_hand_medium_skin_tone:',\n",
       " 'ğŸ”›': ':ON!_arrow:',\n",
       " 'ğŸ…¾': ':O_button_(blood_type):',\n",
       " 'ğŸ‡´ğŸ‡²': ':Oman:',\n",
       " 'â›': ':Ophiuchus:',\n",
       " 'ğŸ…¿': ':P_button:',\n",
       " 'ğŸ‡µğŸ‡°': ':Pakistan:',\n",
       " 'ğŸ‡µğŸ‡¼': ':Palau:',\n",
       " 'ğŸ‡µğŸ‡¸': ':Palestinian_Territories:',\n",
       " 'ğŸ‡µğŸ‡¦': ':Panama:',\n",
       " 'ğŸ‡µğŸ‡¬': ':Papua_New_Guinea:',\n",
       " 'ğŸ‡µğŸ‡¾': ':Paraguay:',\n",
       " 'ğŸ‡µğŸ‡ª': ':Peru:',\n",
       " 'ğŸ‡µğŸ‡­': ':Philippines:',\n",
       " 'â™“': ':Pisces:',\n",
       " 'ğŸ‡µğŸ‡³': ':Pitcairn_Islands:',\n",
       " 'ğŸ‡µğŸ‡±': ':Poland:',\n",
       " 'ğŸ‡µğŸ‡¹': ':Portugal:',\n",
       " 'ğŸ‡µğŸ‡·': ':Puerto_Rico:',\n",
       " 'ğŸ‡¶ğŸ‡¦': ':Qatar:',\n",
       " 'ğŸ‡·ğŸ‡´': ':Romania:',\n",
       " 'ğŸ‡·ğŸ‡º': ':Russia:',\n",
       " 'ğŸ‡·ğŸ‡¼': ':Rwanda:',\n",
       " 'ğŸ‡·ğŸ‡ª': ':RÃ©union:',\n",
       " 'ğŸ”œ': ':SOON_arrow:',\n",
       " 'ğŸ†˜': ':SOS_button:',\n",
       " 'â™': ':Sagittarius:',\n",
       " 'ğŸ‡¼ğŸ‡¸': ':Samoa:',\n",
       " 'ğŸ‡¸ğŸ‡²': ':San_Marino:',\n",
       " 'ğŸ…': ':Santa_Claus:',\n",
       " 'ğŸ…ğŸ¿': ':Santa_Claus_dark_skin_tone:',\n",
       " 'ğŸ…ğŸ»': ':Santa_Claus_light_skin_tone:',\n",
       " 'ğŸ…ğŸ¾': ':Santa_Claus_medium-dark_skin_tone:',\n",
       " 'ğŸ…ğŸ¼': ':Santa_Claus_medium-light_skin_tone:',\n",
       " 'ğŸ…ğŸ½': ':Santa_Claus_medium_skin_tone:',\n",
       " 'ğŸ‡¸ğŸ‡¦': ':Saudi_Arabia:',\n",
       " 'â™': ':Scorpio:',\n",
       " 'ğŸ´\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f': ':Scotland:',\n",
       " 'ğŸ‡¸ğŸ‡³': ':Senegal:',\n",
       " 'ğŸ‡·ğŸ‡¸': ':Serbia:',\n",
       " 'ğŸ‡¸ğŸ‡¨': ':Seychelles:',\n",
       " 'ğŸ‡¸ğŸ‡±': ':Sierra_Leone:',\n",
       " 'ğŸ‡¸ğŸ‡¬': ':Singapore:',\n",
       " 'ğŸ‡¸ğŸ‡½': ':Sint_Maarten:',\n",
       " 'ğŸ‡¸ğŸ‡°': ':Slovakia:',\n",
       " 'ğŸ‡¸ğŸ‡®': ':Slovenia:',\n",
       " 'ğŸ‡¸ğŸ‡§': ':Solomon_Islands:',\n",
       " 'ğŸ‡¸ğŸ‡´': ':Somalia:',\n",
       " 'ğŸ‡¿ğŸ‡¦': ':South_Africa:',\n",
       " 'ğŸ‡¬ğŸ‡¸': ':South_Georgia_&_South_Sandwich_Islands:',\n",
       " 'ğŸ‡°ğŸ‡·': ':South_Korea:',\n",
       " 'ğŸ‡¸ğŸ‡¸': ':South_Sudan:',\n",
       " 'ğŸ‡ªğŸ‡¸': ':Spain:',\n",
       " 'ğŸ‡±ğŸ‡°': ':Sri_Lanka:',\n",
       " 'ğŸ‡§ğŸ‡±': ':St._BarthÃ©lemy:',\n",
       " 'ğŸ‡¸ğŸ‡­': ':St._Helena:',\n",
       " 'ğŸ‡°ğŸ‡³': ':St._Kitts_&_Nevis:',\n",
       " 'ğŸ‡±ğŸ‡¨': ':St._Lucia:',\n",
       " 'ğŸ‡²ğŸ‡«': ':St._Martin:',\n",
       " 'ğŸ‡µğŸ‡²': ':St._Pierre_&_Miquelon:',\n",
       " 'ğŸ‡»ğŸ‡¨': ':St._Vincent_&_Grenadines:',\n",
       " 'ğŸ—½': ':Statue_of_Liberty:',\n",
       " 'ğŸ‡¸ğŸ‡©': ':Sudan:',\n",
       " 'ğŸ‡¸ğŸ‡·': ':Suriname:',\n",
       " 'ğŸ‡¸ğŸ‡¯': ':Svalbard_&_Jan_Mayen:',\n",
       " 'ğŸ‡¸ğŸ‡ª': ':Sweden:',\n",
       " 'ğŸ‡¨ğŸ‡­': ':Switzerland:',\n",
       " 'ğŸ‡¸ğŸ‡¾': ':Syria:',\n",
       " 'ğŸ‡¸ğŸ‡¹': ':SÃ£o_TomÃ©_&_PrÃ­ncipe:',\n",
       " 'ğŸ¦–': ':T-Rex:',\n",
       " 'ğŸ”': ':TOP_arrow:',\n",
       " 'ğŸ‡¹ğŸ‡¼': ':Taiwan:',\n",
       " 'ğŸ‡¹ğŸ‡¯': ':Tajikistan:',\n",
       " 'ğŸ‡¹ğŸ‡¿': ':Tanzania:',\n",
       " 'â™‰': ':Taurus:',\n",
       " 'ğŸ‡¹ğŸ‡­': ':Thailand:',\n",
       " 'ğŸ‡¹ğŸ‡±': ':Timor-Leste:',\n",
       " 'ğŸ‡¹ğŸ‡¬': ':Togo:',\n",
       " 'ğŸ‡¹ğŸ‡°': ':Tokelau:',\n",
       " 'ğŸ—¼': ':Tokyo_tower:',\n",
       " 'ğŸ‡¹ğŸ‡´': ':Tonga:',\n",
       " 'ğŸ‡¹ğŸ‡¹': ':Trinidad_&_Tobago:',\n",
       " 'ğŸ‡¹ğŸ‡¦': ':Tristan_da_Cunha:',\n",
       " 'ğŸ‡¹ğŸ‡³': ':Tunisia:',\n",
       " 'ğŸ‡¹ğŸ‡·': ':Turkey:',\n",
       " 'ğŸ‡¹ğŸ‡²': ':Turkmenistan:',\n",
       " 'ğŸ‡¹ğŸ‡¨': ':Turks_&_Caicos_Islands:',\n",
       " 'ğŸ‡¹ğŸ‡»': ':Tuvalu:',\n",
       " 'ğŸ‡ºğŸ‡²': ':U.S._Outlying_Islands:',\n",
       " 'ğŸ‡»ğŸ‡®': ':U.S._Virgin_Islands:',\n",
       " 'ğŸ†™': ':UP!_button:',\n",
       " 'ğŸ‡ºğŸ‡¬': ':Uganda:',\n",
       " 'ğŸ‡ºğŸ‡¦': ':Ukraine:',\n",
       " 'ğŸ‡¦ğŸ‡ª': ':United_Arab_Emirates:',\n",
       " 'ğŸ‡¬ğŸ‡§': ':United_Kingdom:',\n",
       " 'ğŸ‡ºğŸ‡³': ':United_Nations:',\n",
       " 'ğŸ‡ºğŸ‡¸': ':United_States:',\n",
       " 'ğŸ‡ºğŸ‡¾': ':Uruguay:',\n",
       " 'ğŸ‡ºğŸ‡¿': ':Uzbekistan:',\n",
       " 'ğŸ†š': ':VS_button:',\n",
       " 'ğŸ‡»ğŸ‡º': ':Vanuatu:',\n",
       " 'ğŸ‡»ğŸ‡¦': ':Vatican_City:',\n",
       " 'ğŸ‡»ğŸ‡ª': ':Venezuela:',\n",
       " 'ğŸ‡»ğŸ‡³': ':Vietnam:',\n",
       " 'â™': ':Virgo:',\n",
       " 'ğŸ´\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f': ':Wales:',\n",
       " 'ğŸ‡¼ğŸ‡«': ':Wallis_&_Futuna:',\n",
       " 'ğŸ‡ªğŸ‡­': ':Western_Sahara:',\n",
       " 'ğŸ‡¾ğŸ‡ª': ':Yemen:',\n",
       " 'ğŸ‡¿ğŸ‡²': ':Zambia:',\n",
       " 'ğŸ‡¿ğŸ‡¼': ':Zimbabwe:',\n",
       " 'ğŸ§®': ':abacus:',\n",
       " '\\U0001fa97': ':accordion:',\n",
       " 'ğŸ©¹': ':adhesive_bandage:',\n",
       " 'ğŸŸ': ':admission_tickets:',\n",
       " 'ğŸš¡': ':aerial_tramway:',\n",
       " 'âœˆ': ':airplane:',\n",
       " 'ğŸ›¬': ':airplane_arrival:',\n",
       " 'ğŸ›«': ':airplane_departure:',\n",
       " 'â°': ':alarm_clock:',\n",
       " 'âš—': ':alembic:',\n",
       " 'ğŸ‘½': ':alien:',\n",
       " 'ğŸ‘¾': ':alien_monster:',\n",
       " 'ğŸš‘': ':ambulance:',\n",
       " 'ğŸˆ': ':american_football:',\n",
       " 'ğŸº': ':amphora:',\n",
       " '\\U0001fac0': ':anatomical_heart:',\n",
       " 'âš“': ':anchor:',\n",
       " 'ğŸ’¢': ':anger_symbol:',\n",
       " 'ğŸ˜ ': ':angry_face:',\n",
       " 'ğŸ‘¿': ':angry_face_with_horns:',\n",
       " 'ğŸ˜§': ':anguished_face:',\n",
       " 'ğŸœ': ':ant:',\n",
       " 'ğŸ“¶': ':antenna_bars:',\n",
       " 'ğŸ˜°': ':anxious_face_with_sweat:',\n",
       " 'ğŸš›': ':articulated_lorry:',\n",
       " 'ğŸ§‘\\u200dğŸ¨': ':artist:',\n",
       " 'ğŸ§‘ğŸ¿\\u200dğŸ¨': ':artist_dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ»\\u200dğŸ¨': ':artist_light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¾\\u200dğŸ¨': ':artist_medium-dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¼\\u200dğŸ¨': ':artist_medium-light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ½\\u200dğŸ¨': ':artist_medium_skin_tone:',\n",
       " 'ğŸ¨': ':artist_palette:',\n",
       " 'ğŸ˜²': ':astonished_face:',\n",
       " 'ğŸ§‘\\u200dğŸš€': ':astronaut:',\n",
       " 'ğŸ§‘ğŸ¿\\u200dğŸš€': ':astronaut_dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ»\\u200dğŸš€': ':astronaut_light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¾\\u200dğŸš€': ':astronaut_medium-dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¼\\u200dğŸš€': ':astronaut_medium-light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ½\\u200dğŸš€': ':astronaut_medium_skin_tone:',\n",
       " 'âš›': ':atom_symbol:',\n",
       " 'ğŸ›º': ':auto_rickshaw:',\n",
       " 'ğŸš—': ':automobile:',\n",
       " 'ğŸ¥‘': ':avocado:',\n",
       " 'ğŸª“': ':axe:',\n",
       " 'ğŸ‘¶': ':baby:',\n",
       " 'ğŸ‘¼': ':baby_angel:',\n",
       " 'ğŸ‘¼ğŸ¿': ':baby_angel_dark_skin_tone:',\n",
       " 'ğŸ‘¼ğŸ»': ':baby_angel_light_skin_tone:',\n",
       " 'ğŸ‘¼ğŸ¾': ':baby_angel_medium-dark_skin_tone:',\n",
       " 'ğŸ‘¼ğŸ¼': ':baby_angel_medium-light_skin_tone:',\n",
       " 'ğŸ‘¼ğŸ½': ':baby_angel_medium_skin_tone:',\n",
       " 'ğŸ¼': ':baby_bottle:',\n",
       " 'ğŸ¤': ':baby_chick:',\n",
       " 'ğŸ‘¶ğŸ¿': ':baby_dark_skin_tone:',\n",
       " 'ğŸ‘¶ğŸ»': ':baby_light_skin_tone:',\n",
       " 'ğŸ‘¶ğŸ¾': ':baby_medium-dark_skin_tone:',\n",
       " 'ğŸ‘¶ğŸ¼': ':baby_medium-light_skin_tone:',\n",
       " 'ğŸ‘¶ğŸ½': ':baby_medium_skin_tone:',\n",
       " 'ğŸš¼': ':baby_symbol:',\n",
       " 'ğŸ‘‡': ':backhand_index_pointing_down:',\n",
       " 'ğŸ‘‡ğŸ¿': ':backhand_index_pointing_down_dark_skin_tone:',\n",
       " 'ğŸ‘‡ğŸ»': ':backhand_index_pointing_down_light_skin_tone:',\n",
       " 'ğŸ‘‡ğŸ¾': ':backhand_index_pointing_down_medium-dark_skin_tone:',\n",
       " 'ğŸ‘‡ğŸ¼': ':backhand_index_pointing_down_medium-light_skin_tone:',\n",
       " 'ğŸ‘‡ğŸ½': ':backhand_index_pointing_down_medium_skin_tone:',\n",
       " 'ğŸ‘ˆ': ':backhand_index_pointing_left:',\n",
       " 'ğŸ‘ˆğŸ¿': ':backhand_index_pointing_left_dark_skin_tone:',\n",
       " 'ğŸ‘ˆğŸ»': ':backhand_index_pointing_left_light_skin_tone:',\n",
       " 'ğŸ‘ˆğŸ¾': ':backhand_index_pointing_left_medium-dark_skin_tone:',\n",
       " 'ğŸ‘ˆğŸ¼': ':backhand_index_pointing_left_medium-light_skin_tone:',\n",
       " 'ğŸ‘ˆğŸ½': ':backhand_index_pointing_left_medium_skin_tone:',\n",
       " 'ğŸ‘‰': ':backhand_index_pointing_right:',\n",
       " 'ğŸ‘‰ğŸ¿': ':backhand_index_pointing_right_dark_skin_tone:',\n",
       " 'ğŸ‘‰ğŸ»': ':backhand_index_pointing_right_light_skin_tone:',\n",
       " 'ğŸ‘‰ğŸ¾': ':backhand_index_pointing_right_medium-dark_skin_tone:',\n",
       " 'ğŸ‘‰ğŸ¼': ':backhand_index_pointing_right_medium-light_skin_tone:',\n",
       " 'ğŸ‘‰ğŸ½': ':backhand_index_pointing_right_medium_skin_tone:',\n",
       " 'ğŸ‘†': ':backhand_index_pointing_up:',\n",
       " 'ğŸ‘†ğŸ¿': ':backhand_index_pointing_up_dark_skin_tone:',\n",
       " 'ğŸ‘†ğŸ»': ':backhand_index_pointing_up_light_skin_tone:',\n",
       " 'ğŸ‘†ğŸ¾': ':backhand_index_pointing_up_medium-dark_skin_tone:',\n",
       " 'ğŸ‘†ğŸ¼': ':backhand_index_pointing_up_medium-light_skin_tone:',\n",
       " 'ğŸ‘†ğŸ½': ':backhand_index_pointing_up_medium_skin_tone:',\n",
       " 'ğŸ’': ':backpack:',\n",
       " 'ğŸ¥“': ':bacon:',\n",
       " 'ğŸ¦¡': ':badger:',\n",
       " 'ğŸ¸': ':badminton:',\n",
       " 'ğŸ¥¯': ':bagel:',\n",
       " 'ğŸ›„': ':baggage_claim:',\n",
       " 'ğŸ¥–': ':baguette_bread:',\n",
       " 'âš–': ':balance_scale:',\n",
       " 'ğŸ¦²': ':bald:',\n",
       " 'ğŸ©°': ':ballet_shoes:',\n",
       " 'ğŸˆ': ':balloon:',\n",
       " 'ğŸ—³': ':ballot_box_with_ballot:',\n",
       " 'ğŸŒ': ':banana:',\n",
       " 'ğŸª•': ':banjo:',\n",
       " 'ğŸ¦': ':bank:',\n",
       " 'ğŸ“Š': ':bar_chart:',\n",
       " 'ğŸ’ˆ': ':barber_pole:',\n",
       " 'âš¾': ':baseball:',\n",
       " 'ğŸ§º': ':basket:',\n",
       " 'ğŸ€': ':basketball:',\n",
       " 'ğŸ¦‡': ':bat:',\n",
       " 'ğŸ›': ':bathtub:',\n",
       " 'ğŸ”‹': ':battery:',\n",
       " 'ğŸ–': ':beach_with_umbrella:',\n",
       " 'ğŸ˜': ':beaming_face_with_smiling_eyes:',\n",
       " 'ğŸ»': ':bear:',\n",
       " 'ğŸ’“': ':beating_heart:',\n",
       " '\\U0001f9ab': ':beaver:',\n",
       " 'ğŸ›': ':bed:',\n",
       " 'ğŸº': ':beer_mug:',\n",
       " '\\U0001fab2': ':beetle:',\n",
       " 'ğŸ””': ':bell:',\n",
       " '\\U0001fad1': ':bell_pepper:',\n",
       " 'ğŸ”•': ':bell_with_slash:',\n",
       " 'ğŸ›': ':bellhop_bell:',\n",
       " 'ğŸ±': ':bento_box:',\n",
       " 'ğŸ§ƒ': ':beverage_box:',\n",
       " 'ğŸš²': ':bicycle:',\n",
       " 'ğŸ‘™': ':bikini:',\n",
       " 'ğŸ§¢': ':billed_cap:',\n",
       " 'â˜£': ':biohazard:',\n",
       " 'ğŸ¦': ':bird:',\n",
       " 'ğŸ‚': ':birthday_cake:',\n",
       " '\\U0001f9ac': ':bison:',\n",
       " 'ğŸˆ\\u200dâ¬›': ':black_cat:',\n",
       " 'âš«': ':black_circle:',\n",
       " 'ğŸ´': ':black_flag:',\n",
       " 'ğŸ–¤': ':black_heart:',\n",
       " 'â¬›': ':black_large_square:',\n",
       " 'â—¾': ':black_medium-small_square:',\n",
       " 'â—¼': ':black_medium_square:',\n",
       " 'âœ’': ':black_nib:',\n",
       " 'â–ª': ':black_small_square:',\n",
       " 'ğŸ”²': ':black_square_button:',\n",
       " 'ğŸŒ¼': ':blossom:',\n",
       " 'ğŸ¡': ':blowfish:',\n",
       " 'ğŸ“˜': ':blue_book:',\n",
       " 'ğŸ”µ': ':blue_circle:',\n",
       " 'ğŸ’™': ':blue_heart:',\n",
       " 'ğŸŸ¦': ':blue_square:',\n",
       " '\\U0001fad0': ':blueberries:',\n",
       " 'ğŸ—': ':boar:',\n",
       " 'ğŸ’£': ':bomb:',\n",
       " 'ğŸ¦´': ':bone:',\n",
       " 'ğŸ”–': ':bookmark:',\n",
       " 'ğŸ“‘': ':bookmark_tabs:',\n",
       " 'ğŸ“š': ':books:',\n",
       " '\\U0001fa83': ':boomerang:',\n",
       " 'ğŸ¾': ':bottle_with_popping_cork:',\n",
       " 'ğŸ’': ':bouquet:',\n",
       " 'ğŸ¹': ':bow_and_arrow:',\n",
       " 'ğŸ¥£': ':bowl_with_spoon:',\n",
       " 'ğŸ³': ':bowling:',\n",
       " 'ğŸ¥Š': ':boxing_glove:',\n",
       " 'ğŸ‘¦': ':boy:',\n",
       " 'ğŸ‘¦ğŸ¿': ':boy_dark_skin_tone:',\n",
       " 'ğŸ‘¦ğŸ»': ':boy_light_skin_tone:',\n",
       " 'ğŸ‘¦ğŸ¾': ':boy_medium-dark_skin_tone:',\n",
       " 'ğŸ‘¦ğŸ¼': ':boy_medium-light_skin_tone:',\n",
       " 'ğŸ‘¦ğŸ½': ':boy_medium_skin_tone:',\n",
       " 'ğŸ§ ': ':brain:',\n",
       " 'ğŸ': ':bread:',\n",
       " 'ğŸ¤±': ':breast-feeding:',\n",
       " 'ğŸ¤±ğŸ¿': ':breast-feeding_dark_skin_tone:',\n",
       " 'ğŸ¤±ğŸ»': ':breast-feeding_light_skin_tone:',\n",
       " 'ğŸ¤±ğŸ¾': ':breast-feeding_medium-dark_skin_tone:',\n",
       " 'ğŸ¤±ğŸ¼': ':breast-feeding_medium-light_skin_tone:',\n",
       " 'ğŸ¤±ğŸ½': ':breast-feeding_medium_skin_tone:',\n",
       " 'ğŸ§±': ':brick:',\n",
       " 'ğŸŒ‰': ':bridge_at_night:',\n",
       " 'ğŸ’¼': ':briefcase:',\n",
       " 'ğŸ©²': ':briefs:',\n",
       " 'ğŸ”†': ':bright_button:',\n",
       " 'ğŸ¥¦': ':broccoli:',\n",
       " 'ğŸ’”': ':broken_heart:',\n",
       " 'ğŸ§¹': ':broom:',\n",
       " 'ğŸŸ¤': ':brown_circle:',\n",
       " 'ğŸ¤': ':brown_heart:',\n",
       " 'ğŸŸ«': ':brown_square:',\n",
       " '\\U0001f9cb': ':bubble_tea:',\n",
       " '\\U0001faa3': ':bucket:',\n",
       " 'ğŸ›': ':bug:',\n",
       " 'ğŸ—': ':building_construction:',\n",
       " 'ğŸš…': ':bullet_train:',\n",
       " 'ğŸ¯': ':bullseye:',\n",
       " 'ğŸŒ¯': ':burrito:',\n",
       " 'ğŸšŒ': ':bus:',\n",
       " 'ğŸš': ':bus_stop:',\n",
       " 'ğŸ‘¤': ':bust_in_silhouette:',\n",
       " 'ğŸ‘¥': ':busts_in_silhouette:',\n",
       " 'ğŸ§ˆ': ':butter:',\n",
       " 'ğŸ¦‹': ':butterfly:',\n",
       " 'ğŸŒµ': ':cactus:',\n",
       " 'ğŸ“…': ':calendar:',\n",
       " 'ğŸ¤™': ':call_me_hand:',\n",
       " 'ğŸ¤™ğŸ¿': ':call_me_hand_dark_skin_tone:',\n",
       " 'ğŸ¤™ğŸ»': ':call_me_hand_light_skin_tone:',\n",
       " 'ğŸ¤™ğŸ¾': ':call_me_hand_medium-dark_skin_tone:',\n",
       " 'ğŸ¤™ğŸ¼': ':call_me_hand_medium-light_skin_tone:',\n",
       " 'ğŸ¤™ğŸ½': ':call_me_hand_medium_skin_tone:',\n",
       " 'ğŸª': ':camel:',\n",
       " 'ğŸ“·': ':camera:',\n",
       " 'ğŸ“¸': ':camera_with_flash:',\n",
       " 'ğŸ•': ':camping:',\n",
       " 'ğŸ•¯': ':candle:',\n",
       " 'ğŸ¬': ':candy:',\n",
       " 'ğŸ¥«': ':canned_food:',\n",
       " 'ğŸ›¶': ':canoe:',\n",
       " 'ğŸ—ƒ': ':card_file_box:',\n",
       " 'ğŸ“‡': ':card_index:',\n",
       " 'ğŸ—‚': ':card_index_dividers:',\n",
       " 'ğŸ ': ':carousel_horse:',\n",
       " 'ğŸ': ':carp_streamer:',\n",
       " '\\U0001fa9a': ':carpentry_saw:',\n",
       " 'ğŸ¥•': ':carrot:',\n",
       " 'ğŸ°': ':castle:',\n",
       " 'ğŸˆ': ':cat:',\n",
       " 'ğŸ±': ':cat_face:',\n",
       " 'ğŸ˜¹': ':cat_with_tears_of_joy:',\n",
       " 'ğŸ˜¼': ':cat_with_wry_smile:',\n",
       " 'â›“': ':chains:',\n",
       " 'ğŸª‘': ':chair:',\n",
       " 'ğŸ“‰': ':chart_decreasing:',\n",
       " 'ğŸ“ˆ': ':chart_increasing:',\n",
       " 'ğŸ’¹': ':chart_increasing_with_yen:',\n",
       " 'â˜‘': ':check_box_with_check:',\n",
       " 'âœ”': ':check_mark:',\n",
       " 'âœ…': ':check_mark_button:',\n",
       " 'ğŸ§€': ':cheese_wedge:',\n",
       " 'ğŸ': ':chequered_flag:',\n",
       " 'ğŸ’': ':cherries:',\n",
       " 'ğŸŒ¸': ':cherry_blossom:',\n",
       " 'â™Ÿ': ':chess_pawn:',\n",
       " 'ğŸŒ°': ':chestnut:',\n",
       " 'ğŸ”': ':chicken:',\n",
       " 'ğŸ§’': ':child:',\n",
       " 'ğŸ§’ğŸ¿': ':child_dark_skin_tone:',\n",
       " 'ğŸ§’ğŸ»': ':child_light_skin_tone:',\n",
       " 'ğŸ§’ğŸ¾': ':child_medium-dark_skin_tone:',\n",
       " 'ğŸ§’ğŸ¼': ':child_medium-light_skin_tone:',\n",
       " 'ğŸ§’ğŸ½': ':child_medium_skin_tone:',\n",
       " 'ğŸš¸': ':children_crossing:',\n",
       " 'ğŸ¿': ':chipmunk:',\n",
       " 'ğŸ«': ':chocolate_bar:',\n",
       " 'ğŸ¥¢': ':chopsticks:',\n",
       " 'â›ª': ':church:',\n",
       " 'ğŸš¬': ':cigarette:',\n",
       " 'ğŸ¦': ':cinema:',\n",
       " 'â“‚': ':circled_M:',\n",
       " 'ğŸª': ':circus_tent:',\n",
       " 'ğŸ™': ':cityscape:',\n",
       " 'ğŸŒ†': ':cityscape_at_dusk:',\n",
       " 'ğŸ—œ': ':clamp:',\n",
       " 'ğŸ¬': ':clapper_board:',\n",
       " 'ğŸ‘': ':clapping_hands:',\n",
       " 'ğŸ‘ğŸ¿': ':clapping_hands_dark_skin_tone:',\n",
       " 'ğŸ‘ğŸ»': ':clapping_hands_light_skin_tone:',\n",
       " 'ğŸ‘ğŸ¾': ':clapping_hands_medium-dark_skin_tone:',\n",
       " 'ğŸ‘ğŸ¼': ':clapping_hands_medium-light_skin_tone:',\n",
       " 'ğŸ‘ğŸ½': ':clapping_hands_medium_skin_tone:',\n",
       " 'ğŸ›': ':classical_building:',\n",
       " 'ğŸ»': ':clinking_beer_mugs:',\n",
       " 'ğŸ¥‚': ':clinking_glasses:',\n",
       " 'ğŸ“‹': ':clipboard:',\n",
       " 'ğŸ”ƒ': ':clockwise_vertical_arrows:',\n",
       " 'ğŸ“•': ':closed_book:',\n",
       " 'ğŸ“ª': ':closed_mailbox_with_lowered_flag:',\n",
       " 'ğŸ“«': ':closed_mailbox_with_raised_flag:',\n",
       " 'ğŸŒ‚': ':closed_umbrella:',\n",
       " 'â˜': ':cloud:',\n",
       " 'ğŸŒ©': ':cloud_with_lightning:',\n",
       " 'â›ˆ': ':cloud_with_lightning_and_rain:',\n",
       " 'ğŸŒ§': ':cloud_with_rain:',\n",
       " 'ğŸŒ¨': ':cloud_with_snow:',\n",
       " 'ğŸ¤¡': ':clown_face:',\n",
       " 'â™£': ':club_suit:',\n",
       " 'ğŸ‘': ':clutch_bag:',\n",
       " 'ğŸ§¥': ':coat:',\n",
       " '\\U0001fab3': ':cockroach:',\n",
       " 'ğŸ¸': ':cocktail_glass:',\n",
       " 'ğŸ¥¥': ':coconut:',\n",
       " 'âš°': ':coffin:',\n",
       " '\\U0001fa99': ':coin:',\n",
       " 'ğŸ¥¶': ':cold_face:',\n",
       " 'ğŸ’¥': ':collision:',\n",
       " 'â˜„': ':comet:',\n",
       " 'ğŸ§­': ':compass:',\n",
       " 'ğŸ’½': ':computer_disk:',\n",
       " 'ğŸ–±': ':computer_mouse:',\n",
       " 'ğŸŠ': ':confetti_ball:',\n",
       " 'ğŸ˜–': ':confounded_face:',\n",
       " 'ğŸ˜•': ':confused_face:',\n",
       " 'ğŸš§': ':construction:',\n",
       " 'ğŸ‘·': ':construction_worker:',\n",
       " 'ğŸ‘·ğŸ¿': ':construction_worker_dark_skin_tone:',\n",
       " 'ğŸ‘·ğŸ»': ':construction_worker_light_skin_tone:',\n",
       " 'ğŸ‘·ğŸ¾': ':construction_worker_medium-dark_skin_tone:',\n",
       " 'ğŸ‘·ğŸ¼': ':construction_worker_medium-light_skin_tone:',\n",
       " 'ğŸ‘·ğŸ½': ':construction_worker_medium_skin_tone:',\n",
       " 'ğŸ›': ':control_knobs:',\n",
       " 'ğŸª': ':convenience_store:',\n",
       " 'ğŸ§‘\\u200dğŸ³': ':cook:',\n",
       " 'ğŸ§‘ğŸ¿\\u200dğŸ³': ':cook_dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ»\\u200dğŸ³': ':cook_light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¾\\u200dğŸ³': ':cook_medium-dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¼\\u200dğŸ³': ':cook_medium-light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ½\\u200dğŸ³': ':cook_medium_skin_tone:',\n",
       " 'ğŸš': ':cooked_rice:',\n",
       " 'ğŸª': ':cookie:',\n",
       " 'ğŸ³': ':cooking:',\n",
       " 'Â©': ':copyright:',\n",
       " 'ğŸ›‹': ':couch_and_lamp:',\n",
       " 'ğŸ”„': ':counterclockwise_arrows_button:',\n",
       " 'ğŸ’‘': ':couple_with_heart:',\n",
       " 'ğŸ’‘ğŸ¿': ':couple_with_heart_dark_skin_tone:',\n",
       " 'ğŸ’‘ğŸ»': ':couple_with_heart_light_skin_tone:',\n",
       " 'ğŸ‘¨\\u200dâ¤ï¸\\u200dğŸ‘¨': ':couple_with_heart_man_man:',\n",
       " 'ğŸ‘¨ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_man_man_dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_man_man_dark_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_man_man_dark_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_man_man_dark_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_man_man_dark_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_man_man_light_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_man_man_light_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_man_man_light_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_man_man_light_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_man_man_light_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_man_man_medium-dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_man_man_medium-dark_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_man_man_medium-dark_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_man_man_medium-dark_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_man_man_medium-dark_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_man_man_medium-light_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_man_man_medium-light_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_man_man_medium-light_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_man_man_medium-light_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_man_man_medium-light_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_man_man_medium_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_man_man_medium_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_man_man_medium_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_man_man_medium_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘¨ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_man_man_medium_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ’‘ğŸ¾': ':couple_with_heart_medium-dark_skin_tone:',\n",
       " 'ğŸ’‘ğŸ¼': ':couple_with_heart_medium-light_skin_tone:',\n",
       " 'ğŸ’‘ğŸ½': ':couple_with_heart_medium_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¿\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ»': ':couple_with_heart_person_person_dark_skin_tone_light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¿\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¾': ':couple_with_heart_person_person_dark_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¿\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¼': ':couple_with_heart_person_person_dark_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¿\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ½': ':couple_with_heart_person_person_dark_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ§‘ğŸ»\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¿': ':couple_with_heart_person_person_light_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ»\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¾': ':couple_with_heart_person_person_light_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ»\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¼': ':couple_with_heart_person_person_light_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ»\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ½': ':couple_with_heart_person_person_light_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¾\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¿': ':couple_with_heart_person_person_medium-dark_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¾\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ»': ':couple_with_heart_person_person_medium-dark_skin_tone_light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¾\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¼': ':couple_with_heart_person_person_medium-dark_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¾\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ½': ':couple_with_heart_person_person_medium-dark_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¼\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¿': ':couple_with_heart_person_person_medium-light_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¼\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ»': ':couple_with_heart_person_person_medium-light_skin_tone_light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¼\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¾': ':couple_with_heart_person_person_medium-light_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¼\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ½': ':couple_with_heart_person_person_medium-light_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ§‘ğŸ½\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¿': ':couple_with_heart_person_person_medium_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ½\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ»': ':couple_with_heart_person_person_medium_skin_tone_light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ½\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¾': ':couple_with_heart_person_person_medium_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ½\\u200dâ¤ï¸\\u200dğŸ§‘ğŸ¼': ':couple_with_heart_person_person_medium_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘¨': ':couple_with_heart_woman_man:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_woman_man_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_woman_man_dark_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_woman_man_dark_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_woman_man_dark_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_woman_man_dark_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_woman_man_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_woman_man_light_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_woman_man_light_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_woman_man_light_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_woman_man_light_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_woman_man_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_woman_man_medium-dark_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_woman_man_medium-dark_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_woman_man_medium-dark_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_woman_man_medium-dark_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_woman_man_medium-light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_woman_man_medium-light_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_woman_man_medium-light_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_woman_man_medium-light_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_woman_man_medium-light_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ½': ':couple_with_heart_woman_man_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¿': ':couple_with_heart_woman_man_medium_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ»': ':couple_with_heart_woman_man_medium_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¾': ':couple_with_heart_woman_man_medium_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘¨ğŸ¼': ':couple_with_heart_woman_man_medium_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘©': ':couple_with_heart_woman_woman:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¿': ':couple_with_heart_woman_woman_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ»': ':couple_with_heart_woman_woman_dark_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¾': ':couple_with_heart_woman_woman_dark_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¼': ':couple_with_heart_woman_woman_dark_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¿\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ½': ':couple_with_heart_woman_woman_dark_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ»': ':couple_with_heart_woman_woman_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¿': ':couple_with_heart_woman_woman_light_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¾': ':couple_with_heart_woman_woman_light_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¼': ':couple_with_heart_woman_woman_light_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ»\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ½': ':couple_with_heart_woman_woman_light_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¾': ':couple_with_heart_woman_woman_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¿': ':couple_with_heart_woman_woman_medium-dark_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ»': ':couple_with_heart_woman_woman_medium-dark_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¼': ':couple_with_heart_woman_woman_medium-dark_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¾\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ½': ':couple_with_heart_woman_woman_medium-dark_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¼': ':couple_with_heart_woman_woman_medium-light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¿': ':couple_with_heart_woman_woman_medium-light_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ»': ':couple_with_heart_woman_woman_medium-light_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¾': ':couple_with_heart_woman_woman_medium-light_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ¼\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ½': ':couple_with_heart_woman_woman_medium-light_skin_tone_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ½': ':couple_with_heart_woman_woman_medium_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¿': ':couple_with_heart_woman_woman_medium_skin_tone_dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ»': ':couple_with_heart_woman_woman_medium_skin_tone_light_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¾': ':couple_with_heart_woman_woman_medium_skin_tone_medium-dark_skin_tone:',\n",
       " 'ğŸ‘©ğŸ½\\u200dâ¤ï¸\\u200dğŸ‘©ğŸ¼': ':couple_with_heart_woman_woman_medium_skin_tone_medium-light_skin_tone:',\n",
       " 'ğŸ„': ':cow:',\n",
       " 'ğŸ®': ':cow_face:',\n",
       " 'ğŸ¤ ': ':cowboy_hat_face:',\n",
       " 'ğŸ¦€': ':crab:',\n",
       " 'ğŸ–': ':crayon:',\n",
       " 'ğŸ’³': ':credit_card:',\n",
       " 'ğŸŒ™': ':crescent_moon:',\n",
       " 'ğŸ¦—': ':cricket:',\n",
       " 'ğŸ': ':cricket_game:',\n",
       " 'ğŸŠ': ':crocodile:',\n",
       " 'ğŸ¥': ':croissant:',\n",
       " 'âŒ': ':cross_mark:',\n",
       " 'â': ':cross_mark_button:',\n",
       " 'ğŸ¤': ':crossed_fingers:',\n",
       " 'ğŸ¤ğŸ¿': ':crossed_fingers_dark_skin_tone:',\n",
       " 'ğŸ¤ğŸ»': ':crossed_fingers_light_skin_tone:',\n",
       " 'ğŸ¤ğŸ¾': ':crossed_fingers_medium-dark_skin_tone:',\n",
       " 'ğŸ¤ğŸ¼': ':crossed_fingers_medium-light_skin_tone:',\n",
       " 'ğŸ¤ğŸ½': ':crossed_fingers_medium_skin_tone:',\n",
       " 'ğŸŒ': ':crossed_flags:',\n",
       " 'âš”': ':crossed_swords:',\n",
       " 'ğŸ‘‘': ':crown:',\n",
       " 'ğŸ˜¿': ':crying_cat:',\n",
       " 'ğŸ˜¢': ':crying_face:',\n",
       " 'ğŸ”®': ':crystal_ball:',\n",
       " 'ğŸ¥’': ':cucumber:',\n",
       " 'ğŸ¥¤': ':cup_with_straw:',\n",
       " 'ğŸ§': ':cupcake:',\n",
       " 'ğŸ¥Œ': ':curling_stone:',\n",
       " 'ğŸ¦±': ':curly_hair:',\n",
       " 'â°': ':curly_loop:',\n",
       " 'ğŸ’±': ':currency_exchange:',\n",
       " 'ğŸ›': ':curry_rice:',\n",
       " 'ğŸ®': ':custard:',\n",
       " 'ğŸ›ƒ': ':customs:',\n",
       " 'ğŸ¥©': ':cut_of_meat:',\n",
       " 'ğŸŒ€': ':cyclone:',\n",
       " 'ğŸ—¡': ':dagger:',\n",
       " 'ğŸ¡': ':dango:',\n",
       " 'ğŸ¿': ':dark_skin_tone:',\n",
       " 'ğŸ’¨': ':dashing_away:',\n",
       " 'ğŸ§\\u200dâ™‚ï¸': ':deaf_man:',\n",
       " 'ğŸ§ğŸ¿\\u200dâ™‚ï¸': ':deaf_man_dark_skin_tone:',\n",
       " 'ğŸ§ğŸ»\\u200dâ™‚ï¸': ':deaf_man_light_skin_tone:',\n",
       " 'ğŸ§ğŸ¾\\u200dâ™‚ï¸': ':deaf_man_medium-dark_skin_tone:',\n",
       " 'ğŸ§ğŸ¼\\u200dâ™‚ï¸': ':deaf_man_medium-light_skin_tone:',\n",
       " 'ğŸ§ğŸ½\\u200dâ™‚ï¸': ':deaf_man_medium_skin_tone:',\n",
       " 'ğŸ§': ':deaf_person:',\n",
       " 'ğŸ§ğŸ¿': ':deaf_person_dark_skin_tone:',\n",
       " 'ğŸ§ğŸ»': ':deaf_person_light_skin_tone:',\n",
       " 'ğŸ§ğŸ¾': ':deaf_person_medium-dark_skin_tone:',\n",
       " 'ğŸ§ğŸ¼': ':deaf_person_medium-light_skin_tone:',\n",
       " 'ğŸ§ğŸ½': ':deaf_person_medium_skin_tone:',\n",
       " 'ğŸ§\\u200dâ™€ï¸': ':deaf_woman:',\n",
       " 'ğŸ§ğŸ¿\\u200dâ™€ï¸': ':deaf_woman_dark_skin_tone:',\n",
       " 'ğŸ§ğŸ»\\u200dâ™€ï¸': ':deaf_woman_light_skin_tone:',\n",
       " 'ğŸ§ğŸ¾\\u200dâ™€ï¸': ':deaf_woman_medium-dark_skin_tone:',\n",
       " 'ğŸ§ğŸ¼\\u200dâ™€ï¸': ':deaf_woman_medium-light_skin_tone:',\n",
       " 'ğŸ§ğŸ½\\u200dâ™€ï¸': ':deaf_woman_medium_skin_tone:',\n",
       " 'ğŸŒ³': ':deciduous_tree:',\n",
       " 'ğŸ¦Œ': ':deer:',\n",
       " 'ğŸšš': ':delivery_truck:',\n",
       " 'ğŸ¬': ':department_store:',\n",
       " 'ğŸš': ':derelict_house:',\n",
       " 'ğŸœ': ':desert:',\n",
       " 'ğŸ': ':desert_island:',\n",
       " 'ğŸ–¥': ':desktop_computer:',\n",
       " 'ğŸ•µ': ':detective:',\n",
       " 'ğŸ•µğŸ¿': ':detective_dark_skin_tone:',\n",
       " 'ğŸ•µğŸ»': ':detective_light_skin_tone:',\n",
       " 'ğŸ•µğŸ¾': ':detective_medium-dark_skin_tone:',\n",
       " 'ğŸ•µğŸ¼': ':detective_medium-light_skin_tone:',\n",
       " 'ğŸ•µğŸ½': ':detective_medium_skin_tone:',\n",
       " 'â™¦': ':diamond_suit:',\n",
       " 'ğŸ’ ': ':diamond_with_a_dot:',\n",
       " 'ğŸ”…': ':dim_button:',\n",
       " 'ğŸ˜': ':disappointed_face:',\n",
       " '\\U0001f978': ':disguised_face:',\n",
       " 'â—': ':divide:',\n",
       " 'ğŸ¤¿': ':diving_mask:',\n",
       " 'ğŸª”': ':diya_lamp:',\n",
       " 'ğŸ’«': ':dizzy:',\n",
       " 'ğŸ§¬': ':dna:',\n",
       " '\\U0001f9a4': ':dodo:',\n",
       " 'ğŸ•': ':dog:',\n",
       " 'ğŸ¶': ':dog_face:',\n",
       " 'ğŸ’µ': ':dollar_banknote:',\n",
       " 'ğŸ¬': ':dolphin:',\n",
       " 'ğŸšª': ':door:',\n",
       " 'ğŸ”¯': ':dotted_six-pointed_star:',\n",
       " 'â¿': ':double_curly_loop:',\n",
       " 'â€¼': ':double_exclamation_mark:',\n",
       " 'ğŸ©': ':doughnut:',\n",
       " 'ğŸ•Š': ':dove:',\n",
       " 'â†™': ':down-left_arrow:',\n",
       " 'â†˜': ':down-right_arrow:',\n",
       " 'â¬‡': ':down_arrow:',\n",
       " 'ğŸ˜“': ':downcast_face_with_sweat:',\n",
       " 'ğŸ”½': ':downwards_button:',\n",
       " 'ğŸ‰': ':dragon:',\n",
       " 'ğŸ²': ':dragon_face:',\n",
       " 'ğŸ‘—': ':dress:',\n",
       " 'ğŸ¤¤': ':drooling_face:',\n",
       " 'ğŸ©¸': ':drop_of_blood:',\n",
       " 'ğŸ’§': ':droplet:',\n",
       " 'ğŸ¥': ':drum:',\n",
       " 'ğŸ¦†': ':duck:',\n",
       " 'ğŸ¥Ÿ': ':dumpling:',\n",
       " 'ğŸ“€': ':dvd:',\n",
       " 'ğŸ“§': ':e-mail:',\n",
       " 'ğŸ¦…': ':eagle:',\n",
       " 'ğŸ‘‚': ':ear:',\n",
       " 'ğŸ‘‚ğŸ¿': ':ear_dark_skin_tone:',\n",
       " 'ğŸ‘‚ğŸ»': ':ear_light_skin_tone:',\n",
       " 'ğŸ‘‚ğŸ¾': ':ear_medium-dark_skin_tone:',\n",
       " 'ğŸ‘‚ğŸ¼': ':ear_medium-light_skin_tone:',\n",
       " 'ğŸ‘‚ğŸ½': ':ear_medium_skin_tone:',\n",
       " 'ğŸŒ½': ':ear_of_corn:',\n",
       " 'ğŸ¦»': ':ear_with_hearing_aid:',\n",
       " 'ğŸ¦»ğŸ¿': ':ear_with_hearing_aid_dark_skin_tone:',\n",
       " 'ğŸ¦»ğŸ»': ':ear_with_hearing_aid_light_skin_tone:',\n",
       " 'ğŸ¦»ğŸ¾': ':ear_with_hearing_aid_medium-dark_skin_tone:',\n",
       " 'ğŸ¦»ğŸ¼': ':ear_with_hearing_aid_medium-light_skin_tone:',\n",
       " 'ğŸ¦»ğŸ½': ':ear_with_hearing_aid_medium_skin_tone:',\n",
       " 'ğŸ¥š': ':egg:',\n",
       " 'ğŸ†': ':eggplant:',\n",
       " 'âœ´': ':eight-pointed_star:',\n",
       " 'âœ³': ':eight-spoked_asterisk:',\n",
       " 'ğŸ•£': ':eight-thirty:',\n",
       " 'ğŸ•—': ':eight_oâ€™clock:',\n",
       " 'â': ':eject_button:',\n",
       " 'ğŸ”Œ': ':electric_plug:',\n",
       " 'ğŸ˜': ':elephant:',\n",
       " '\\U0001f6d7': ':elevator:',\n",
       " 'ğŸ•¦': ':eleven-thirty:',\n",
       " 'ğŸ•š': ':eleven_oâ€™clock:',\n",
       " 'ğŸ§': ':elf:',\n",
       " 'ğŸ§ğŸ¿': ':elf_dark_skin_tone:',\n",
       " 'ğŸ§ğŸ»': ':elf_light_skin_tone:',\n",
       " 'ğŸ§ğŸ¾': ':elf_medium-dark_skin_tone:',\n",
       " 'ğŸ§ğŸ¼': ':elf_medium-light_skin_tone:',\n",
       " 'ğŸ§ğŸ½': ':elf_medium_skin_tone:',\n",
       " 'âœ‰': ':envelope:',\n",
       " 'ğŸ“©': ':envelope_with_arrow:',\n",
       " 'ğŸ’¶': ':euro_banknote:',\n",
       " 'ğŸŒ²': ':evergreen_tree:',\n",
       " 'ğŸ‘': ':ewe:',\n",
       " 'â‰': ':exclamation_question_mark:',\n",
       " 'ğŸ¤¯': ':exploding_head:',\n",
       " 'ğŸ˜‘': ':expressionless_face:',\n",
       " 'ğŸ‘': ':eye:',\n",
       " 'ğŸ‘ï¸\\u200dğŸ—¨ï¸': ':eye_in_speech_bubble:',\n",
       " 'ğŸ‘€': ':eyes:',\n",
       " 'ğŸ˜˜': ':face_blowing_a_kiss:',\n",
       " 'ğŸ˜®\\u200dğŸ’¨': ':face_exhaling:',\n",
       " 'ğŸ˜¶\\u200dğŸŒ«ï¸': ':face_in_clouds:',\n",
       " 'ğŸ˜‹': ':face_savoring_food:',\n",
       " 'ğŸ˜±': ':face_screaming_in_fear:',\n",
       " 'ğŸ¤®': ':face_vomiting:',\n",
       " 'ğŸ¤­': ':face_with_hand_over_mouth:',\n",
       " 'ğŸ¤•': ':face_with_head-bandage:',\n",
       " 'ğŸ˜·': ':face_with_medical_mask:',\n",
       " 'ğŸ§': ':face_with_monocle:',\n",
       " 'ğŸ˜®': ':face_with_open_mouth:',\n",
       " 'ğŸ¤¨': ':face_with_raised_eyebrow:',\n",
       " 'ğŸ™„': ':face_with_rolling_eyes:',\n",
       " 'ğŸ˜µ\\u200dğŸ’«': ':face_with_spiral_eyes:',\n",
       " 'ğŸ˜¤': ':face_with_steam_from_nose:',\n",
       " 'ğŸ¤¬': ':face_with_symbols_on_mouth:',\n",
       " 'ğŸ˜‚': ':face_with_tears_of_joy:',\n",
       " 'ğŸ¤’': ':face_with_thermometer:',\n",
       " 'ğŸ˜›': ':face_with_tongue:',\n",
       " 'ğŸ˜¶': ':face_without_mouth:',\n",
       " 'ğŸ­': ':factory:',\n",
       " 'ğŸ§‘\\u200dğŸ­': ':factory_worker:',\n",
       " 'ğŸ§‘ğŸ¿\\u200dğŸ­': ':factory_worker_dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ»\\u200dğŸ­': ':factory_worker_light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¾\\u200dğŸ­': ':factory_worker_medium-dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¼\\u200dğŸ­': ':factory_worker_medium-light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ½\\u200dğŸ­': ':factory_worker_medium_skin_tone:',\n",
       " 'ğŸ§š': ':fairy:',\n",
       " 'ğŸ§šğŸ¿': ':fairy_dark_skin_tone:',\n",
       " 'ğŸ§šğŸ»': ':fairy_light_skin_tone:',\n",
       " 'ğŸ§šğŸ¾': ':fairy_medium-dark_skin_tone:',\n",
       " 'ğŸ§šğŸ¼': ':fairy_medium-light_skin_tone:',\n",
       " 'ğŸ§šğŸ½': ':fairy_medium_skin_tone:',\n",
       " 'ğŸ§†': ':falafel:',\n",
       " 'ğŸ‚': ':fallen_leaf:',\n",
       " 'ğŸ‘ª': ':family:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘¦': ':family_man_boy:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘¦\\u200dğŸ‘¦': ':family_man_boy_boy:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘§': ':family_man_girl:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘¦': ':family_man_girl_boy:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘§': ':family_man_girl_girl:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘¦': ':family_man_man_boy:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘¦\\u200dğŸ‘¦': ':family_man_man_boy_boy:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘§': ':family_man_man_girl:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘¦': ':family_man_man_girl_boy:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘§': ':family_man_man_girl_girl:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘¦': ':family_man_woman_boy:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘¦\\u200dğŸ‘¦': ':family_man_woman_boy_boy:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§': ':family_man_woman_girl:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦': ':family_man_woman_girl_boy:',\n",
       " 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘§': ':family_man_woman_girl_girl:',\n",
       " 'ğŸ‘©\\u200dğŸ‘¦': ':family_woman_boy:',\n",
       " 'ğŸ‘©\\u200dğŸ‘¦\\u200dğŸ‘¦': ':family_woman_boy_boy:',\n",
       " 'ğŸ‘©\\u200dğŸ‘§': ':family_woman_girl:',\n",
       " 'ğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦': ':family_woman_girl_boy:',\n",
       " 'ğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘§': ':family_woman_girl_girl:',\n",
       " 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘¦': ':family_woman_woman_boy:',\n",
       " 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘¦\\u200dğŸ‘¦': ':family_woman_woman_boy_boy:',\n",
       " 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘§': ':family_woman_woman_girl:',\n",
       " 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦': ':family_woman_woman_girl_boy:',\n",
       " 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘§': ':family_woman_woman_girl_girl:',\n",
       " 'ğŸ§‘\\u200dğŸŒ¾': ':farmer:',\n",
       " 'ğŸ§‘ğŸ¿\\u200dğŸŒ¾': ':farmer_dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ»\\u200dğŸŒ¾': ':farmer_light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¾\\u200dğŸŒ¾': ':farmer_medium-dark_skin_tone:',\n",
       " 'ğŸ§‘ğŸ¼\\u200dğŸŒ¾': ':farmer_medium-light_skin_tone:',\n",
       " 'ğŸ§‘ğŸ½\\u200dğŸŒ¾': ':farmer_medium_skin_tone:',\n",
       " 'â©': ':fast-forward_button:',\n",
       " 'â¬': ':fast_down_button:',\n",
       " 'âª': ':fast_reverse_button:',\n",
       " 'â«': ':fast_up_button:',\n",
       " 'ğŸ“ ': ':fax_machine:',\n",
       " 'ğŸ˜¨': ':fearful_face:',\n",
       " '\\U0001fab6': ':feather:',\n",
       " 'â™€': ':female_sign:',\n",
       " 'ğŸ¡': ':ferris_wheel:',\n",
       " 'â›´': ':ferry:',\n",
       " 'ğŸ‘': ':field_hockey:',\n",
       " 'ğŸ—„': ':file_cabinet:',\n",
       " 'ğŸ“': ':file_folder:',\n",
       " 'ğŸ': ':film_frames:',\n",
       " 'ğŸ“½': ':film_projector:',\n",
       " 'ğŸ”¥': ':fire:',\n",
       " 'ğŸš’': ':fire_engine:',\n",
       " 'ğŸ§¯': ':fire_extinguisher:',\n",
       " 'ğŸ§¨': ':firecracker:',\n",
       " 'ğŸ§‘\\u200dğŸš’': ':firefighter:',\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_emojis(text):\n",
    "#     for emot in UNICODE_EMOJI:\n",
    "#         text = re.sub(r'('+emot+')', \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'me' in STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_stopword']=df['basic_cleaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_stopword'] = df['no_stopword'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'someone tell'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('can someone tell me how she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to deal with # (tags); how to deal with 2 emojis # how to deal with !&?; Chat Words Conversion e.g. wtf/lmk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72359     picard gotcha day february th kept sane throug...\n",
       "117238                                            hound nap\n",
       "74310                                             breakfast\n",
       "110206                      finally figured socks disappear\n",
       "49964                           walter postsurgery dinosaur\n",
       "                                ...                        \n",
       "32080                                                  cool\n",
       "6865                                          little piglet\n",
       "121554                                 border collie forest\n",
       "43425                     difference winter summer coat dog\n",
       "133671    big red practicing selfcontrol would ever gues...\n",
       "Name: no_stopword, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['no_stopword']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_stopword'] = df.no_stopword.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72359     [picard, gotcha, day, february, th, kept, sane...\n",
       "117238                                         [hound, nap]\n",
       "74310                                           [breakfast]\n",
       "110206                 [finally, figured, socks, disappear]\n",
       "49964                       [walter, postsurgery, dinosaur]\n",
       "105794                          [first, look, lovely, john]\n",
       "40869                                 [say, sleeping, good]\n",
       "92190                                  [chillin, long, day]\n",
       "57167                                 [hail, king, baby, ğŸ‘‘]\n",
       "109746                      [akitan, family, everyday, day]\n",
       "54282            [good, boy, ringing, new, year, dogquilla]\n",
       "49350            [strolling, turin, saw, adorable, puppies]\n",
       "4870               [eating, dirt, majestic, three, seconds]\n",
       "80003     [lost, maki, yesterday, blood, cancer, know, e...\n",
       "132276                                        [dog, cooler]\n",
       "70254              [parents, last, borzoi, first, labrador]\n",
       "129993               [today, found, long, stick, fantastic]\n",
       "128627                                           [goofball]\n",
       "85970                              [happy, holidays, doggo]\n",
       "108056    [goodest, boi, probably, wished, new, parents,...\n",
       "134630               [always, get, comments, tail, showing]\n",
       "8419                                        [deleted, user]\n",
       "25492                                       [deleted, user]\n",
       "72868                               [wifes, working, thing]\n",
       "104408                             [good, girls, good, boi]\n",
       "35193                                  [morning, inversion]\n",
       "106645                     [sweet, pup, entropion, surgery]\n",
       "34905                                   [digging, backyard]\n",
       "128719    [best, friend, left, us, long, battle, cancer,...\n",
       "5751                   [little, old, man, people, watching]\n",
       "Name: no_stopword, dtype: object"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['no_stopword'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemma(text):\n",
    "    lemmatizer = WordNetLemmatizer() # Instantiate lemmatizer\n",
    "    lemmatized_n = [lemmatizer.lemmatize(word,pos='n') for word in text]\n",
    "#     print(lemmatized_n)\n",
    "    lemmatized_v = [lemmatizer.lemmatize(word,pos='v') for word in lemmatized_n] \n",
    "#     print(lemmatized_v)\n",
    "#     cleaned_sentence = ' '.join(word for word in lemmatized_v)\n",
    "#     return cleaned_sentence\n",
    "    return lemmatized_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatize'] = df['no_stopword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatize'] = df['lemmatize'].apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72359     [picard, gotcha, day, february, th, keep, sane...\n",
       "117238                                         [hound, nap]\n",
       "74310                                           [breakfast]\n",
       "110206                   [finally, figure, sock, disappear]\n",
       "49964                       [walter, postsurgery, dinosaur]\n",
       "105794                          [first, look, lovely, john]\n",
       "40869                                    [say, sleep, good]\n",
       "92190                                  [chillin, long, day]\n",
       "57167                                 [hail, king, baby, ğŸ‘‘]\n",
       "109746                      [akitan, family, everyday, day]\n",
       "54282               [good, boy, ring, new, year, dogquilla]\n",
       "49350                 [stroll, turin, saw, adorable, puppy]\n",
       "4870                   [eat, dirt, majestic, three, second]\n",
       "80003     [lose, maki, yesterday, blood, cancer, know, e...\n",
       "132276                                        [dog, cooler]\n",
       "70254               [parent, last, borzoi, first, labrador]\n",
       "129993                [today, find, long, stick, fantastic]\n",
       "128627                                           [goofball]\n",
       "85970                               [happy, holiday, doggo]\n",
       "108056    [goodest, boi, probably, wish, new, parent, em...\n",
       "Name: lemmatize, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatize'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the length of each title (Need to split all the words and emoji beforehand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lemma = df['lemmatize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot deal with abbreviation; doin; cannot seperate emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tokenizer **Don't NEED NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rd/q2lzfdss4b167026m7l6h8pm0000gn/T/ipykernel_38433/4228307245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_feature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_preprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCenterCrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_preprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomCrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_preprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomFlip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage_preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimeseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# This exists for compatibility with prior version of keras_preprocessing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/utils/all_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_source_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_gpu_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/utils/multi_gpu_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mHDF5_OBJECT_HEADER_LIMIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/h5py/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# --- Public API --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5pl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_hl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36minit h5py.h5f\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(df.lemmatize)\n",
    "df['tokenized']=tk.texts_to_sequences(df.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>title</th>\n",
       "      <th>Image_url</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>no_stopword</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26379</th>\n",
       "      <td>26379</td>\n",
       "      <td>nu260w</td>\n",
       "      <td>1.623034e+09</td>\n",
       "      <td>patriot poms macieall black pom  pinning her b...</td>\n",
       "      <td>https://i.redd.it/41g91fvzbr371.png</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>[patriot, poms, macieall, black, pom, pinning,...</td>\n",
       "      <td>[patriot, pom, macieall, black, pom, pin, baby...</td>\n",
       "      <td>[3413, 902, 3414, 247, 902, 3415, 27, 9, 1129,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46598</th>\n",
       "      <td>46598</td>\n",
       "      <td>g3c9su</td>\n",
       "      <td>1.587163e+09</td>\n",
       "      <td>flora our golden retriever</td>\n",
       "      <td>https://i.redd.it/mj6cwtm1igt41.jpg</td>\n",
       "      <td>0.91</td>\n",
       "      <td>28</td>\n",
       "      <td>[flora, golden, retriever]</td>\n",
       "      <td>[flora, golden, retriever]</td>\n",
       "      <td>[3416, 166, 356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58211</th>\n",
       "      <td>58211</td>\n",
       "      <td>cwg55z</td>\n",
       "      <td>1.566968e+09</td>\n",
       "      <td>does anybody know what kind of dog this is we ...</td>\n",
       "      <td>https://i.redd.it/b0zcwy7of4j31.jpg</td>\n",
       "      <td>0.95</td>\n",
       "      <td>15</td>\n",
       "      <td>[anybody, know, kind, dog, found, stray, exact...</td>\n",
       "      <td>[anybody, know, kind, dog, find, stray, exactl...</td>\n",
       "      <td>[686, 44, 344, 1, 57, 497, 809, 147, 50, 1, 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13796</th>\n",
       "      <td>13796</td>\n",
       "      <td>sr2itc</td>\n",
       "      <td>1.644704e+09</td>\n",
       "      <td>my american bulldog puppy</td>\n",
       "      <td>https://i.redd.it/7w5hzqvn6hh81.jpg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[american, bulldog, puppy]</td>\n",
       "      <td>[american, bulldog, puppy]</td>\n",
       "      <td>[470, 296, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17481</th>\n",
       "      <td>17481</td>\n",
       "      <td>r7izrl</td>\n",
       "      <td>1.638484e+09</td>\n",
       "      <td>mac chewer of the stick love life by the river</td>\n",
       "      <td>https://www.reddit.com/gallery/r7izrl</td>\n",
       "      <td>0.91</td>\n",
       "      <td>15</td>\n",
       "      <td>[mac, chewer, stick, love, life, river]</td>\n",
       "      <td>[mac, chewer, stick, love, life, river]</td>\n",
       "      <td>[1512, 3417, 122, 3, 43, 563]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23443</th>\n",
       "      <td>23443</td>\n",
       "      <td>oy6wi5</td>\n",
       "      <td>1.628126e+09</td>\n",
       "      <td>my baby boy gunner a new father</td>\n",
       "      <td>https://i.redd.it/8l48os1lwff71.jpg</td>\n",
       "      <td>0.94</td>\n",
       "      <td>13</td>\n",
       "      <td>[baby, boy, gunner, new, father]</td>\n",
       "      <td>[baby, boy, gunner, new, father]</td>\n",
       "      <td>[27, 4, 1012, 15, 1130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23954</th>\n",
       "      <td>23954</td>\n",
       "      <td>orlr1p</td>\n",
       "      <td>1.627253e+09</td>\n",
       "      <td>good girl had a stroke she lived  dog years ho...</td>\n",
       "      <td>https://i.redd.it/9dsiq2udsfd71.jpg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[good, girl, stroke, lived, dog, years, hope, ...</td>\n",
       "      <td>[good, girl, stroke, live, dog, year, hope, sh...</td>\n",
       "      <td>[10, 9, 1847, 192, 1, 6, 195, 24, 205, 597, 286]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42796</th>\n",
       "      <td>42796</td>\n",
       "      <td>hjtt2d</td>\n",
       "      <td>1.593681e+09</td>\n",
       "      <td>success</td>\n",
       "      <td>https://i.redd.it/0150bbtove851.jpg</td>\n",
       "      <td>0.95</td>\n",
       "      <td>108</td>\n",
       "      <td>[success]</td>\n",
       "      <td>[success]</td>\n",
       "      <td>[1513]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15633</th>\n",
       "      <td>15633</td>\n",
       "      <td>ryus2n</td>\n",
       "      <td>1.641629e+09</td>\n",
       "      <td>lost my baby girl a year ago today she got ran...</td>\n",
       "      <td>https://i.redd.it/bjv509ij7fa81.jpg</td>\n",
       "      <td>0.94</td>\n",
       "      <td>15</td>\n",
       "      <td>[lost, baby, girl, year, ago, today, got, ran,...</td>\n",
       "      <td>[lose, baby, girl, year, ago, today, get, run,...</td>\n",
       "      <td>[162, 27, 9, 6, 73, 17, 2, 151, 21, 7, 185, 7,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14393</th>\n",
       "      <td>14393</td>\n",
       "      <td>sifa5d</td>\n",
       "      <td>1.643776e+09</td>\n",
       "      <td>my dod in a christmas sweater ğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥º do u like it</td>\n",
       "      <td>https://www.reddit.com/gallery/sifa5d</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[dod, christmas, sweater, ğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥º, u, like]</td>\n",
       "      <td>[dod, christmas, sweater, ğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥º, u, like]</td>\n",
       "      <td>[3418, 87, 1013, 3419, 80, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85833</th>\n",
       "      <td>85833</td>\n",
       "      <td>7z2u58</td>\n",
       "      <td>1.519188e+09</td>\n",
       "      <td>lbs of pure love and devotion</td>\n",
       "      <td>https://i.redd.it/mtpatbumvhh01.jpg</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5</td>\n",
       "      <td>[lbs, pure, love, devotion]</td>\n",
       "      <td>[lb, pure, love, devotion]</td>\n",
       "      <td>[428, 564, 3, 2363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27951</th>\n",
       "      <td>27951</td>\n",
       "      <td>n6xl3k</td>\n",
       "      <td>1.620391e+09</td>\n",
       "      <td>leia having a great time with her friend at th...</td>\n",
       "      <td>https://i.imgur.com/y1BrS3g.jpg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>[leia, great, time, friend, pier]</td>\n",
       "      <td>[leia, great, time, friend, pier]</td>\n",
       "      <td>[1514, 112, 22, 19, 2364]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98173</th>\n",
       "      <td>98173</td>\n",
       "      <td>6ho7nh</td>\n",
       "      <td>1.497636e+09</td>\n",
       "      <td>sadie took her first boat ride today</td>\n",
       "      <td>https://i.redd.it/o1l2od80r14z.jpg</td>\n",
       "      <td>0.96</td>\n",
       "      <td>26</td>\n",
       "      <td>[sadie, took, first, boat, ride, today]</td>\n",
       "      <td>[sadie, take, first, boat, ride, today]</td>\n",
       "      <td>[408, 25, 21, 499, 163, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88726</th>\n",
       "      <td>88726</td>\n",
       "      <td>7lxt1d</td>\n",
       "      <td>1.514153e+09</td>\n",
       "      <td>xanders rd christmas</td>\n",
       "      <td>http://imgur.com/clRSuTH</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>[xanders, rd, christmas]</td>\n",
       "      <td>[xanders, rd, christmas]</td>\n",
       "      <td>[3420, 1291, 87]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70956</th>\n",
       "      <td>70956</td>\n",
       "      <td>a6lrpn</td>\n",
       "      <td>1.544930e+09</td>\n",
       "      <td>my elderly dog rubella is so thankful to no lo...</td>\n",
       "      <td>https://i.imgur.com/8kyoMdh.jpg</td>\n",
       "      <td>0.98</td>\n",
       "      <td>387</td>\n",
       "      <td>[elderly, dog, rubella, thankful, longer, live...</td>\n",
       "      <td>[elderly, dog, rubella, thankful, longer, live...</td>\n",
       "      <td>[2365, 1, 3421, 1292, 687, 192, 640, 47, 1848,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11373</th>\n",
       "      <td>11373</td>\n",
       "      <td>tv6vcd</td>\n",
       "      <td>1.648984e+09</td>\n",
       "      <td>meet sherlock this adorable boy melted my heart</td>\n",
       "      <td>https://i.redd.it/7jo2kljlqar81.jpg</td>\n",
       "      <td>0.99</td>\n",
       "      <td>79</td>\n",
       "      <td>[meet, sherlock, adorable, boy, melted, heart]</td>\n",
       "      <td>[meet, sherlock, adorable, boy, melt, heart]</td>\n",
       "      <td>[18, 1515, 215, 4, 389, 138]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31117</th>\n",
       "      <td>31117</td>\n",
       "      <td>lps5u6</td>\n",
       "      <td>1.614010e+09</td>\n",
       "      <td>newest addition to my big family nova</td>\n",
       "      <td>https://i.redd.it/7gxkxn50z1j61.jpg</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2350</td>\n",
       "      <td>[newest, addition, big, family, nova]</td>\n",
       "      <td>[newest, addition, big, family, nova]</td>\n",
       "      <td>[306, 409, 48, 88, 903]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>14107</td>\n",
       "      <td>smrdl1</td>\n",
       "      <td>1.644244e+09</td>\n",
       "      <td>monday equals fun day for big rodney</td>\n",
       "      <td>https://i.redd.it/ot6bp1a37fg81.jpg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2402</td>\n",
       "      <td>[monday, equals, fun, day, big, rodney]</td>\n",
       "      <td>[monday, equal, fun, day, big, rodney]</td>\n",
       "      <td>[500, 1849, 205, 7, 48, 3422]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74945</th>\n",
       "      <td>74945</td>\n",
       "      <td>9jc3rq</td>\n",
       "      <td>1.538048e+09</td>\n",
       "      <td>such a sweet doggo</td>\n",
       "      <td>https://i.imgur.com/BmaiZ6p.jpg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[sweet, doggo]</td>\n",
       "      <td>[sweet, doggo]</td>\n",
       "      <td>[45, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48543</th>\n",
       "      <td>48543</td>\n",
       "      <td>ffpbtf</td>\n",
       "      <td>1.583729e+09</td>\n",
       "      <td>well another pic of my dog</td>\n",
       "      <td>https://i.redd.it/gvov3cprskl41.jpg</td>\n",
       "      <td>0.94</td>\n",
       "      <td>29</td>\n",
       "      <td>[well, another, pic, dog]</td>\n",
       "      <td>[well, another, pic, dog]</td>\n",
       "      <td>[154, 216, 96, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95423</th>\n",
       "      <td>95423</td>\n",
       "      <td>6t1y64</td>\n",
       "      <td>1.502466e+09</td>\n",
       "      <td>this is emma</td>\n",
       "      <td>https://i.redd.it/32xba795p4fz.jpg</td>\n",
       "      <td>0.96</td>\n",
       "      <td>32</td>\n",
       "      <td>[emma]</td>\n",
       "      <td>[emma]</td>\n",
       "      <td>[1293]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50238</th>\n",
       "      <td>50238</td>\n",
       "      <td>eyfo21</td>\n",
       "      <td>1.580770e+09</td>\n",
       "      <td>everyonemeet zeek with his half sister zoey in...</td>\n",
       "      <td>https://i.redd.it/tl0lpprbgse41.jpg</td>\n",
       "      <td>0.96</td>\n",
       "      <td>57</td>\n",
       "      <td>[everyonemeet, zeek, half, sister, zoey, back]</td>\n",
       "      <td>[everyonemeet, zeek, half, sister, zoey, back]</td>\n",
       "      <td>[3423, 3424, 170, 169, 1014, 82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62217</th>\n",
       "      <td>62217</td>\n",
       "      <td>bygib8</td>\n",
       "      <td>1.560054e+09</td>\n",
       "      <td>his name is otis i love him lots</td>\n",
       "      <td>https://i.redd.it/6ymskmqqb9331.jpg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>683</td>\n",
       "      <td>[name, otis, love, lots]</td>\n",
       "      <td>[name, otis, love, lot]</td>\n",
       "      <td>[34, 904, 3, 221]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75642</th>\n",
       "      <td>75642</td>\n",
       "      <td>9fnxi4</td>\n",
       "      <td>1.536889e+09</td>\n",
       "      <td>she was upset we didnt have room on the couch ...</td>\n",
       "      <td>https://i.redd.it/sl3xu3y6z3m11.jpg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>[upset, didnt, room, couch, cuddle]</td>\n",
       "      <td>[upset, didnt, room, couch, cuddle]</td>\n",
       "      <td>[1131, 206, 451, 145, 142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38330</th>\n",
       "      <td>38330</td>\n",
       "      <td>j239sp</td>\n",
       "      <td>1.601399e+09</td>\n",
       "      <td>roscoe is more concerned about my lunch than t...</td>\n",
       "      <td>https://i.imgur.com/qM8aVGU.jpg</td>\n",
       "      <td>0.91</td>\n",
       "      <td>8</td>\n",
       "      <td>[roscoe, concerned, lunch, feather, stuck, nose]</td>\n",
       "      <td>[roscoe, concern, lunch, feather, stick, nose]</td>\n",
       "      <td>[1015, 1016, 1294, 1850, 122, 501]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55805</th>\n",
       "      <td>55805</td>\n",
       "      <td>dilswz</td>\n",
       "      <td>1.571211e+09</td>\n",
       "      <td>speedy welsh springer spaniel out in the first...</td>\n",
       "      <td>https://i.redd.it/s9rjbaqpuus31.jpg</td>\n",
       "      <td>0.91</td>\n",
       "      <td>16</td>\n",
       "      <td>[speedy, welsh, springer, spaniel, first, snow...</td>\n",
       "      <td>[speedy, welsh, springer, spaniel, first, snow...</td>\n",
       "      <td>[1851, 3425, 905, 429, 21, 51, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62975</th>\n",
       "      <td>62975</td>\n",
       "      <td>bsoorj</td>\n",
       "      <td>1.558746e+09</td>\n",
       "      <td>hes a  year old distinguished gentleman</td>\n",
       "      <td>https://i.redd.it/40i1rjln99031.jpg</td>\n",
       "      <td>0.85</td>\n",
       "      <td>18</td>\n",
       "      <td>[hes, year, old, distinguished, gentleman]</td>\n",
       "      <td>[he, year, old, distinguish, gentleman]</td>\n",
       "      <td>[20, 6, 5, 1852, 1017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9394</th>\n",
       "      <td>9394</td>\n",
       "      <td>unzdyq</td>\n",
       "      <td>1.652357e+09</td>\n",
       "      <td>a happy shepherd</td>\n",
       "      <td>https://i.redd.it/nbl02wpdb1z81.jpg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[happy, shepherd]</td>\n",
       "      <td>[happy, shepherd]</td>\n",
       "      <td>[12, 193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48103</th>\n",
       "      <td>48103</td>\n",
       "      <td>fkr3x6</td>\n",
       "      <td>1.584545e+09</td>\n",
       "      <td>just explained to him that well be staying hom...</td>\n",
       "      <td>https://i.redd.it/8xzb9ptx6gn41.jpg</td>\n",
       "      <td>0.97</td>\n",
       "      <td>67</td>\n",
       "      <td>[explained, well, staying, home, bit, least, w...</td>\n",
       "      <td>[explain, well, stay, home, bite, least, week]</td>\n",
       "      <td>[1516, 154, 264, 41, 171, 565, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92076</th>\n",
       "      <td>92076</td>\n",
       "      <td>76v21w</td>\n",
       "      <td>1.508202e+09</td>\n",
       "      <td>years old and he has just enough energy to swi...</td>\n",
       "      <td>https://i.redd.it/z6fw9nxdgasz.jpg</td>\n",
       "      <td>0.99</td>\n",
       "      <td>545</td>\n",
       "      <td>[years, old, enough, energy, swim, water, run,...</td>\n",
       "      <td>[year, old, enough, energy, swim, water, run, ...</td>\n",
       "      <td>[6, 5, 252, 598, 471, 297, 151, 113, 1295, 55]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      id    time_stamp  \\\n",
       "26379       26379  nu260w  1.623034e+09   \n",
       "46598       46598  g3c9su  1.587163e+09   \n",
       "58211       58211  cwg55z  1.566968e+09   \n",
       "13796       13796  sr2itc  1.644704e+09   \n",
       "17481       17481  r7izrl  1.638484e+09   \n",
       "23443       23443  oy6wi5  1.628126e+09   \n",
       "23954       23954  orlr1p  1.627253e+09   \n",
       "42796       42796  hjtt2d  1.593681e+09   \n",
       "15633       15633  ryus2n  1.641629e+09   \n",
       "14393       14393  sifa5d  1.643776e+09   \n",
       "85833       85833  7z2u58  1.519188e+09   \n",
       "27951       27951  n6xl3k  1.620391e+09   \n",
       "98173       98173  6ho7nh  1.497636e+09   \n",
       "88726       88726  7lxt1d  1.514153e+09   \n",
       "70956       70956  a6lrpn  1.544930e+09   \n",
       "11373       11373  tv6vcd  1.648984e+09   \n",
       "31117       31117  lps5u6  1.614010e+09   \n",
       "14107       14107  smrdl1  1.644244e+09   \n",
       "74945       74945  9jc3rq  1.538048e+09   \n",
       "48543       48543  ffpbtf  1.583729e+09   \n",
       "95423       95423  6t1y64  1.502466e+09   \n",
       "50238       50238  eyfo21  1.580770e+09   \n",
       "62217       62217  bygib8  1.560054e+09   \n",
       "75642       75642  9fnxi4  1.536889e+09   \n",
       "38330       38330  j239sp  1.601399e+09   \n",
       "55805       55805  dilswz  1.571211e+09   \n",
       "62975       62975  bsoorj  1.558746e+09   \n",
       "9394         9394  unzdyq  1.652357e+09   \n",
       "48103       48103  fkr3x6  1.584545e+09   \n",
       "92076       92076  76v21w  1.508202e+09   \n",
       "\n",
       "                                                   title  \\\n",
       "26379  patriot poms macieall black pom  pinning her b...   \n",
       "46598                         flora our golden retriever   \n",
       "58211  does anybody know what kind of dog this is we ...   \n",
       "13796                          my american bulldog puppy   \n",
       "17481     mac chewer of the stick love life by the river   \n",
       "23443                    my baby boy gunner a new father   \n",
       "23954  good girl had a stroke she lived  dog years ho...   \n",
       "42796                                            success   \n",
       "15633  lost my baby girl a year ago today she got ran...   \n",
       "14393    my dod in a christmas sweater ğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥º do u like it   \n",
       "85833                      lbs of pure love and devotion   \n",
       "27951  leia having a great time with her friend at th...   \n",
       "98173               sadie took her first boat ride today   \n",
       "88726                               xanders rd christmas   \n",
       "70956  my elderly dog rubella is so thankful to no lo...   \n",
       "11373    meet sherlock this adorable boy melted my heart   \n",
       "31117              newest addition to my big family nova   \n",
       "14107               monday equals fun day for big rodney   \n",
       "74945                                 such a sweet doggo   \n",
       "48543                         well another pic of my dog   \n",
       "95423                                       this is emma   \n",
       "50238  everyonemeet zeek with his half sister zoey in...   \n",
       "62217                   his name is otis i love him lots   \n",
       "75642  she was upset we didnt have room on the couch ...   \n",
       "38330  roscoe is more concerned about my lunch than t...   \n",
       "55805  speedy welsh springer spaniel out in the first...   \n",
       "62975            hes a  year old distinguished gentleman   \n",
       "9394                                    a happy shepherd   \n",
       "48103  just explained to him that well be staying hom...   \n",
       "92076  years old and he has just enough energy to swi...   \n",
       "\n",
       "                                   Image_url  upvote_ratio  upvotes  \\\n",
       "26379    https://i.redd.it/41g91fvzbr371.png          1.00        5   \n",
       "46598    https://i.redd.it/mj6cwtm1igt41.jpg          0.91       28   \n",
       "58211    https://i.redd.it/b0zcwy7of4j31.jpg          0.95       15   \n",
       "13796    https://i.redd.it/7w5hzqvn6hh81.jpg          1.00        1   \n",
       "17481  https://www.reddit.com/gallery/r7izrl          0.91       15   \n",
       "23443    https://i.redd.it/8l48os1lwff71.jpg          0.94       13   \n",
       "23954    https://i.redd.it/9dsiq2udsfd71.jpg          1.00        1   \n",
       "42796    https://i.redd.it/0150bbtove851.jpg          0.95      108   \n",
       "15633    https://i.redd.it/bjv509ij7fa81.jpg          0.94       15   \n",
       "14393  https://www.reddit.com/gallery/sifa5d          1.00        1   \n",
       "85833    https://i.redd.it/mtpatbumvhh01.jpg          0.85        5   \n",
       "27951        https://i.imgur.com/y1BrS3g.jpg          1.00       19   \n",
       "98173     https://i.redd.it/o1l2od80r14z.jpg          0.96       26   \n",
       "88726               http://imgur.com/clRSuTH          1.00       10   \n",
       "70956        https://i.imgur.com/8kyoMdh.jpg          0.98      387   \n",
       "11373    https://i.redd.it/7jo2kljlqar81.jpg          0.99       79   \n",
       "31117    https://i.redd.it/7gxkxn50z1j61.jpg          0.99     2350   \n",
       "14107    https://i.redd.it/ot6bp1a37fg81.jpg          1.00     2402   \n",
       "74945        https://i.imgur.com/BmaiZ6p.jpg          1.00        1   \n",
       "48543    https://i.redd.it/gvov3cprskl41.jpg          0.94       29   \n",
       "95423     https://i.redd.it/32xba795p4fz.jpg          0.96       32   \n",
       "50238    https://i.redd.it/tl0lpprbgse41.jpg          0.96       57   \n",
       "62217    https://i.redd.it/6ymskmqqb9331.jpg          1.00      683   \n",
       "75642    https://i.redd.it/sl3xu3y6z3m11.jpg          1.00        6   \n",
       "38330        https://i.imgur.com/qM8aVGU.jpg          0.91        8   \n",
       "55805    https://i.redd.it/s9rjbaqpuus31.jpg          0.91       16   \n",
       "62975    https://i.redd.it/40i1rjln99031.jpg          0.85       18   \n",
       "9394     https://i.redd.it/nbl02wpdb1z81.jpg          1.00        1   \n",
       "48103    https://i.redd.it/8xzb9ptx6gn41.jpg          0.97       67   \n",
       "92076     https://i.redd.it/z6fw9nxdgasz.jpg          0.99      545   \n",
       "\n",
       "                                             no_stopword  \\\n",
       "26379  [patriot, poms, macieall, black, pom, pinning,...   \n",
       "46598                         [flora, golden, retriever]   \n",
       "58211  [anybody, know, kind, dog, found, stray, exact...   \n",
       "13796                         [american, bulldog, puppy]   \n",
       "17481            [mac, chewer, stick, love, life, river]   \n",
       "23443                   [baby, boy, gunner, new, father]   \n",
       "23954  [good, girl, stroke, lived, dog, years, hope, ...   \n",
       "42796                                          [success]   \n",
       "15633  [lost, baby, girl, year, ago, today, got, ran,...   \n",
       "14393           [dod, christmas, sweater, ğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥º, u, like]   \n",
       "85833                        [lbs, pure, love, devotion]   \n",
       "27951                  [leia, great, time, friend, pier]   \n",
       "98173            [sadie, took, first, boat, ride, today]   \n",
       "88726                           [xanders, rd, christmas]   \n",
       "70956  [elderly, dog, rubella, thankful, longer, live...   \n",
       "11373     [meet, sherlock, adorable, boy, melted, heart]   \n",
       "31117              [newest, addition, big, family, nova]   \n",
       "14107            [monday, equals, fun, day, big, rodney]   \n",
       "74945                                     [sweet, doggo]   \n",
       "48543                          [well, another, pic, dog]   \n",
       "95423                                             [emma]   \n",
       "50238     [everyonemeet, zeek, half, sister, zoey, back]   \n",
       "62217                           [name, otis, love, lots]   \n",
       "75642                [upset, didnt, room, couch, cuddle]   \n",
       "38330   [roscoe, concerned, lunch, feather, stuck, nose]   \n",
       "55805  [speedy, welsh, springer, spaniel, first, snow...   \n",
       "62975         [hes, year, old, distinguished, gentleman]   \n",
       "9394                                   [happy, shepherd]   \n",
       "48103  [explained, well, staying, home, bit, least, w...   \n",
       "92076  [years, old, enough, energy, swim, water, run,...   \n",
       "\n",
       "                                               lemmatize  \\\n",
       "26379  [patriot, pom, macieall, black, pom, pin, baby...   \n",
       "46598                         [flora, golden, retriever]   \n",
       "58211  [anybody, know, kind, dog, find, stray, exactl...   \n",
       "13796                         [american, bulldog, puppy]   \n",
       "17481            [mac, chewer, stick, love, life, river]   \n",
       "23443                   [baby, boy, gunner, new, father]   \n",
       "23954  [good, girl, stroke, live, dog, year, hope, sh...   \n",
       "42796                                          [success]   \n",
       "15633  [lose, baby, girl, year, ago, today, get, run,...   \n",
       "14393           [dod, christmas, sweater, ğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥º, u, like]   \n",
       "85833                         [lb, pure, love, devotion]   \n",
       "27951                  [leia, great, time, friend, pier]   \n",
       "98173            [sadie, take, first, boat, ride, today]   \n",
       "88726                           [xanders, rd, christmas]   \n",
       "70956  [elderly, dog, rubella, thankful, longer, live...   \n",
       "11373       [meet, sherlock, adorable, boy, melt, heart]   \n",
       "31117              [newest, addition, big, family, nova]   \n",
       "14107             [monday, equal, fun, day, big, rodney]   \n",
       "74945                                     [sweet, doggo]   \n",
       "48543                          [well, another, pic, dog]   \n",
       "95423                                             [emma]   \n",
       "50238     [everyonemeet, zeek, half, sister, zoey, back]   \n",
       "62217                            [name, otis, love, lot]   \n",
       "75642                [upset, didnt, room, couch, cuddle]   \n",
       "38330     [roscoe, concern, lunch, feather, stick, nose]   \n",
       "55805  [speedy, welsh, springer, spaniel, first, snow...   \n",
       "62975            [he, year, old, distinguish, gentleman]   \n",
       "9394                                   [happy, shepherd]   \n",
       "48103     [explain, well, stay, home, bite, least, week]   \n",
       "92076  [year, old, enough, energy, swim, water, run, ...   \n",
       "\n",
       "                                               tokenized  \n",
       "26379  [3413, 902, 3414, 247, 902, 3415, 27, 9, 1129,...  \n",
       "46598                                   [3416, 166, 356]  \n",
       "58211  [686, 44, 344, 1, 57, 497, 809, 147, 50, 1, 49...  \n",
       "13796                                     [470, 296, 14]  \n",
       "17481                      [1512, 3417, 122, 3, 43, 563]  \n",
       "23443                            [27, 4, 1012, 15, 1130]  \n",
       "23954   [10, 9, 1847, 192, 1, 6, 195, 24, 205, 597, 286]  \n",
       "42796                                             [1513]  \n",
       "15633  [162, 27, 9, 6, 73, 17, 2, 151, 21, 7, 185, 7,...  \n",
       "14393                     [3418, 87, 1013, 3419, 80, 11]  \n",
       "85833                                [428, 564, 3, 2363]  \n",
       "27951                          [1514, 112, 22, 19, 2364]  \n",
       "98173                        [408, 25, 21, 499, 163, 17]  \n",
       "88726                                   [3420, 1291, 87]  \n",
       "70956  [2365, 1, 3421, 1292, 687, 192, 640, 47, 1848,...  \n",
       "11373                       [18, 1515, 215, 4, 389, 138]  \n",
       "31117                            [306, 409, 48, 88, 903]  \n",
       "14107                      [500, 1849, 205, 7, 48, 3422]  \n",
       "74945                                           [45, 36]  \n",
       "48543                                  [154, 216, 96, 1]  \n",
       "95423                                             [1293]  \n",
       "50238                   [3423, 3424, 170, 169, 1014, 82]  \n",
       "62217                                  [34, 904, 3, 221]  \n",
       "75642                         [1131, 206, 451, 145, 142]  \n",
       "38330                 [1015, 1016, 1294, 1850, 122, 501]  \n",
       "55805                  [1851, 3425, 905, 429, 21, 51, 6]  \n",
       "62975                             [20, 6, 5, 1852, 1017]  \n",
       "9394                                           [12, 193]  \n",
       "48103                 [1516, 154, 264, 41, 171, 565, 39]  \n",
       "92076     [6, 5, 252, 598, 471, 297, 151, 113, 1295, 55]  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 1,\n",
       " 'get': 2,\n",
       " 'boy': 3,\n",
       " 'love': 4,\n",
       " 'old': 5,\n",
       " 'year': 6,\n",
       " 'day': 7,\n",
       " 'delete': 8,\n",
       " 'user': 9,\n",
       " 'happy': 10,\n",
       " 'good': 11,\n",
       " 'girl': 12,\n",
       " 'little': 13,\n",
       " 'like': 14,\n",
       " 'best': 15,\n",
       " 'look': 16,\n",
       " 'today': 17,\n",
       " 'puppy': 18,\n",
       " 'new': 19,\n",
       " 'friend': 20,\n",
       " 'meet': 21,\n",
       " 'take': 22,\n",
       " 'time': 23,\n",
       " 'shes': 24,\n",
       " 'he': 25,\n",
       " 'one': 26,\n",
       " 'month': 27,\n",
       " 'pup': 28,\n",
       " 'go': 29,\n",
       " 'first': 30,\n",
       " 'picture': 31,\n",
       " 'think': 32,\n",
       " 'say': 33,\n",
       " 'im': 34,\n",
       " 'baby': 35,\n",
       " 'want': 36,\n",
       " 'week': 37,\n",
       " 'enjoy': 38,\n",
       " 'doggo': 39,\n",
       " 'sleep': 40,\n",
       " 'sweet': 41,\n",
       " 'make': 42,\n",
       " 'cute': 43,\n",
       " 'walk': 44,\n",
       " 'name': 45,\n",
       " 'breed': 46,\n",
       " 'home': 47,\n",
       " 'mix': 48,\n",
       " 'life': 49,\n",
       " 'know': 50,\n",
       " 'smile': 51,\n",
       " 'miss': 52,\n",
       " 'ago': 53,\n",
       " 'play': 54,\n",
       " 'ever': 55,\n",
       " 'rescue': 56,\n",
       " 'face': 57,\n",
       " 'see': 58,\n",
       " 'big': 59,\n",
       " 'â¤ï¸': 60,\n",
       " 'always': 61,\n",
       " 'beautiful': 62,\n",
       " 'guy': 63,\n",
       " 'still': 64,\n",
       " 'help': 65,\n",
       " 'two': 66,\n",
       " 'find': 67,\n",
       " 'dont': 68,\n",
       " 'much': 69,\n",
       " 'morning': 70,\n",
       " 'eye': 71,\n",
       " 'snow': 72,\n",
       " 'work': 73,\n",
       " 'birthday': 74,\n",
       " 'buddy': 75,\n",
       " 'sit': 76,\n",
       " 'bed': 77,\n",
       " 'favorite': 78,\n",
       " 'turn': 79,\n",
       " 'photo': 80,\n",
       " 'family': 81,\n",
       " 'come': 82,\n",
       " 'leave': 83,\n",
       " 'last': 84,\n",
       " 'handsome': 85,\n",
       " 'ball': 86,\n",
       " 'give': 87,\n",
       " 'tell': 88,\n",
       " 'back': 89,\n",
       " 'adopt': 90,\n",
       " 'ready': 91,\n",
       " 'cant': 92,\n",
       " 'park': 93,\n",
       " 'pupper': 94,\n",
       " 'pic': 95,\n",
       " 'boi': 96,\n",
       " 'wait': 97,\n",
       " 'nap': 98,\n",
       " 'please': 99,\n",
       " 'someone': 100,\n",
       " 'hello': 101,\n",
       " 'toy': 102,\n",
       " 'u': 103,\n",
       " 'try': 104,\n",
       " 'anyone': 105,\n",
       " 'beach': 106,\n",
       " 'hi': 107,\n",
       " 'treat': 108,\n",
       " 'christmas': 109,\n",
       " 'sleepy': 110,\n",
       " 'need': 111,\n",
       " 'pretty': 112,\n",
       " 'right': 113,\n",
       " 'would': 114,\n",
       " 'mom': 115,\n",
       " 'really': 116,\n",
       " 'great': 117,\n",
       " 'could': 118,\n",
       " 'post': 119,\n",
       " 'man': 120,\n",
       " 'husky': 121,\n",
       " 'watch': 122,\n",
       " 'every': 123,\n",
       " 'brother': 124,\n",
       " 'pass': 125,\n",
       " 'bear': 126,\n",
       " 'pet': 127,\n",
       " 'sun': 128,\n",
       " 'here': 129,\n",
       " 'away': 130,\n",
       " 'way': 131,\n",
       " 'reddit': 132,\n",
       " 'night': 133,\n",
       " 'put': 134,\n",
       " 'hike': 135,\n",
       " 'lab': 136,\n",
       " 'feel': 137,\n",
       " 'keep': 138,\n",
       " 'golden': 139,\n",
       " 'share': 140,\n",
       " 'lose': 141,\n",
       " 'house': 142,\n",
       " 'shepherd': 143,\n",
       " 'spot': 144,\n",
       " 'let': 145,\n",
       " 'sister': 146,\n",
       " 'dad': 147,\n",
       " 'doesnt': 148,\n",
       " 'heart': 149,\n",
       " 'long': 150,\n",
       " 'guess': 151,\n",
       " 'around': 152,\n",
       " 'ive': 153,\n",
       " 'catch': 154,\n",
       " 'german': 155,\n",
       " 'yesterday': 156,\n",
       " 'thing': 157,\n",
       " 'never': 158,\n",
       " 'grow': 159,\n",
       " 'cuddle': 160,\n",
       " 'well': 161,\n",
       " 'shoot': 162,\n",
       " 'couch': 163,\n",
       " 'ear': 164,\n",
       " 'cat': 165,\n",
       " 'everyone': 166,\n",
       " 'na': 167,\n",
       " 'eat': 168,\n",
       " 'bring': 169,\n",
       " 'lay': 170,\n",
       " 'run': 171,\n",
       " 'camera': 172,\n",
       " 'pose': 173,\n",
       " 'stick': 174,\n",
       " 'sure': 175,\n",
       " 'world': 176,\n",
       " 'luna': 177,\n",
       " 'even': 178,\n",
       " 'tire': 179,\n",
       " 'finally': 180,\n",
       " 'bite': 181,\n",
       " 'human': 182,\n",
       " 'ride': 183,\n",
       " 'lil': 184,\n",
       " 'part': 185,\n",
       " 'ğŸ˜‚': 186,\n",
       " 'doggy': 187,\n",
       " 'youre': 188,\n",
       " 'call': 189,\n",
       " 'show': 190,\n",
       " 'goodbye': 191,\n",
       " 'better': 192,\n",
       " 'bath': 193,\n",
       " 'use': 194,\n",
       " 'th': 195,\n",
       " 'didnt': 196,\n",
       " 'ğŸ¥°': 197,\n",
       " 'car': 198,\n",
       " 'goodest': 199,\n",
       " 'outside': 200,\n",
       " 'shelter': 201,\n",
       " 'trip': 202,\n",
       " 'together': 203,\n",
       " 'water': 204,\n",
       " 'wish': 205,\n",
       " 'hard': 206,\n",
       " 'ğŸ˜': 207,\n",
       " 'almost': 208,\n",
       " 'doggos': 209,\n",
       " 'photogenic': 210,\n",
       " 'since': 211,\n",
       " 'lol': 212,\n",
       " 'lot': 213,\n",
       " 'rip': 214,\n",
       " 'tongue': 215,\n",
       " 'fall': 216,\n",
       " 'break': 217,\n",
       " 'adorable': 218,\n",
       " 'ğŸ¶': 219,\n",
       " 'yo': 220,\n",
       " 'rest': 221,\n",
       " 'kind': 222,\n",
       " 'max': 223,\n",
       " 'might': 224,\n",
       " 'also': 225,\n",
       " 'summer': 226,\n",
       " 'lucy': 227,\n",
       " 'pillow': 228,\n",
       " 'isnt': 229,\n",
       " 'stop': 230,\n",
       " 'lady': 231,\n",
       " 'without': 232,\n",
       " 'hope': 233,\n",
       " 'ask': 234,\n",
       " 'vet': 235,\n",
       " 'live': 236,\n",
       " 'wake': 237,\n",
       " 'x': 238,\n",
       " 'cross': 239,\n",
       " 'cool': 240,\n",
       " 'warm': 241,\n",
       " 'another': 242,\n",
       " 'cold': 243,\n",
       " 'fast': 244,\n",
       " 'daisy': 245,\n",
       " 'paw': 246,\n",
       " 'already': 247,\n",
       " 'three': 248,\n",
       " 'weekend': 249,\n",
       " 'retriever': 250,\n",
       " 'portrait': 251,\n",
       " 'start': 252,\n",
       " 'people': 253,\n",
       " 'place': 254,\n",
       " 'paint': 255,\n",
       " 'blue': 256,\n",
       " 'decide': 257,\n",
       " 'excite': 258,\n",
       " 'thank': 259,\n",
       " 'couldnt': 260,\n",
       " 'food': 261,\n",
       " 'wear': 262,\n",
       " 'lovely': 263,\n",
       " 'blanket': 264,\n",
       " 'something': 265,\n",
       " 'ill': 266,\n",
       " 'rainbow': 267,\n",
       " 'dude': 268,\n",
       " 'forever': 269,\n",
       " 'cutie': 270,\n",
       " 'sometimes': 271,\n",
       " 'follow': 272,\n",
       " 'lb': 273,\n",
       " 'stay': 274,\n",
       " 'idea': 275,\n",
       " 'nice': 276,\n",
       " 'thats': 277,\n",
       " 'bridge': 278,\n",
       " 'bella': 279,\n",
       " 'side': 280,\n",
       " 'may': 281,\n",
       " 'pick': 282,\n",
       " 'second': 283,\n",
       " 'hour': 284,\n",
       " 'sunday': 285,\n",
       " 'v': 286,\n",
       " 'halloween': 287,\n",
       " 'perfect': 288,\n",
       " 'recently': 289,\n",
       " 'terrier': 290,\n",
       " 'proud': 291,\n",
       " 'lazy': 292,\n",
       " 'id': 293,\n",
       " 'send': 294,\n",
       " 'mini': 295,\n",
       " 'snuggle': 296,\n",
       " 'corgi': 297,\n",
       " 'chihuahua': 298,\n",
       " 'yr': 299,\n",
       " 'teddy': 300,\n",
       " 'next': 301,\n",
       " 'fun': 302,\n",
       " 'leg': 303,\n",
       " 'hear': 304,\n",
       " 'favourite': 305,\n",
       " 'care': 306,\n",
       " 'saw': 307,\n",
       " 'charlie': 308,\n",
       " 'black': 309,\n",
       " 'draw': 310,\n",
       " 'cutest': 311,\n",
       " 'light': 312,\n",
       " 'mr': 313,\n",
       " 'adventure': 314,\n",
       " 'majestic': 315,\n",
       " 'half': 316,\n",
       " 'couple': 317,\n",
       " 'steal': 318,\n",
       " 'road': 319,\n",
       " 'collie': 320,\n",
       " 'beagle': 321,\n",
       " 'amaze': 322,\n",
       " 'owner': 323,\n",
       " 'moment': 324,\n",
       " 'chill': 325,\n",
       " 'model': 326,\n",
       " 'attention': 327,\n",
       " 'mean': 328,\n",
       " 'aussie': 329,\n",
       " 'red': 330,\n",
       " 'enough': 331,\n",
       " 'newest': 332,\n",
       " 'derp': 333,\n",
       " 'hey': 334,\n",
       " 'oh': 335,\n",
       " 'hot': 336,\n",
       " 'nothing': 337,\n",
       " 'holiday': 338,\n",
       " 'whats': 339,\n",
       " 'though': 340,\n",
       " 'winter': 341,\n",
       " 'member': 342,\n",
       " 'full': 343,\n",
       " 'snooze': 344,\n",
       " 'ğŸ¾': 345,\n",
       " 'snoot': 346,\n",
       " 'hit': 347,\n",
       " 'move': 348,\n",
       " 'else': 349,\n",
       " 'gon': 350,\n",
       " 'squirrel': 351,\n",
       " 'foot': 352,\n",
       " 'belly': 353,\n",
       " 'wan': 354,\n",
       " 'game': 355,\n",
       " 'free': 356,\n",
       " 'tonight': 357,\n",
       " 'dinner': 358,\n",
       " 'minute': 359,\n",
       " 'nose': 360,\n",
       " 'national': 361,\n",
       " 'age': 362,\n",
       " 'hang': 363,\n",
       " 'son': 364,\n",
       " 'oc': 365,\n",
       " 'become': 366,\n",
       " 'anything': 367,\n",
       " 'parent': 368,\n",
       " 'king': 369,\n",
       " 'chillin': 370,\n",
       " 'jack': 371,\n",
       " 'head': 372,\n",
       " 'american': 373,\n",
       " 'queen': 374,\n",
       " 'chase': 375,\n",
       " 'bone': 376,\n",
       " 'top': 377,\n",
       " 'st': 378,\n",
       " 'fit': 379,\n",
       " 'foster': 380,\n",
       " 'theyre': 381,\n",
       " 'silly': 382,\n",
       " 'job': 383,\n",
       " 'bailey': 384,\n",
       " 'star': 385,\n",
       " 'hold': 386,\n",
       " 'fur': 387,\n",
       " 'phone': 388,\n",
       " 'spend': 389,\n",
       " 'princess': 390,\n",
       " 'mine': 391,\n",
       " 'comment': 392,\n",
       " 'boop': 393,\n",
       " 'everything': 394,\n",
       " 'fetch': 395,\n",
       " 'crazy': 396,\n",
       " 'asleep': 397,\n",
       " 'saturday': 398,\n",
       " 'ğŸ˜Š': 399,\n",
       " 'animal': 400,\n",
       " 'â¤': 401,\n",
       " 'hand': 402,\n",
       " 'weather': 403,\n",
       " 'lake': 404,\n",
       " 'figure': 405,\n",
       " 'wouldnt': 406,\n",
       " 'ğŸ’•': 407,\n",
       " 'molly': 408,\n",
       " 'bad': 409,\n",
       " 'australian': 410,\n",
       " 'toby': 411,\n",
       " 'die': 412,\n",
       " 'buy': 413,\n",
       " 'flower': 414,\n",
       " 'open': 415,\n",
       " 'cooper': 416,\n",
       " 'past': 417,\n",
       " 'puppers': 418,\n",
       " 'allow': 419,\n",
       " 'monday': 420,\n",
       " 'visit': 421,\n",
       " 'surgery': 422,\n",
       " 'spoil': 423,\n",
       " 'camp': 424,\n",
       " 'hair': 425,\n",
       " 'sweetest': 426,\n",
       " 'bulldog': 427,\n",
       " 'beg': 428,\n",
       " 'poor': 429,\n",
       " 'small': 430,\n",
       " 'office': 431,\n",
       " 'quite': 432,\n",
       " 'swim': 433,\n",
       " 'relax': 434,\n",
       " 'boxer': 435,\n",
       " 'fluffy': 436,\n",
       " 'check': 437,\n",
       " 'cover': 438,\n",
       " 'chow': 439,\n",
       " 'cone': 440,\n",
       " 'jump': 441,\n",
       " 'haircut': 442,\n",
       " 'wife': 443,\n",
       " 'far': 444,\n",
       " 'bud': 445,\n",
       " 'border': 446,\n",
       " 'tiny': 447,\n",
       " 'tail': 448,\n",
       " 'hound': 449,\n",
       " 'yet': 450,\n",
       " 'shiba': 451,\n",
       " 'dexter': 452,\n",
       " 'smell': 453,\n",
       " 'scar': 454,\n",
       " 'end': 455,\n",
       " 'appreciate': 456,\n",
       " 'angel': 457,\n",
       " 'pure': 458,\n",
       " 'special': 459,\n",
       " 'sunshine': 460,\n",
       " 'â€˜': 461,\n",
       " 'ğŸ¥º': 462,\n",
       " 'forget': 463,\n",
       " 'doin': 464,\n",
       " 'rub': 465,\n",
       " 'hat': 466,\n",
       " 'child': 467,\n",
       " 'train': 468,\n",
       " 'street': 469,\n",
       " 'pug': 470,\n",
       " 'wonder': 471,\n",
       " 'type': 472,\n",
       " 'kid': 473,\n",
       " 'giant': 474,\n",
       " 'real': 475,\n",
       " 'kiss': 476,\n",
       " 'brown': 477,\n",
       " 'hooman': 478,\n",
       " 'super': 479,\n",
       " 'maggie': 480,\n",
       " 'floor': 481,\n",
       " 'front': 482,\n",
       " 'dachshund': 483,\n",
       " 'rain': 484,\n",
       " 'short': 485,\n",
       " 'pepper': 486,\n",
       " 'pound': 487,\n",
       " 'definitely': 488,\n",
       " 'whole': 489,\n",
       " 'later': 490,\n",
       " 'wont': 491,\n",
       " 'true': 492,\n",
       " 'seem': 493,\n",
       " 'sadie': 494,\n",
       " 'happiest': 495,\n",
       " 'yes': 496,\n",
       " 'soon': 497,\n",
       " 'yard': 498,\n",
       " 'funny': 499,\n",
       " 'bandit': 500,\n",
       " 'who': 501,\n",
       " 'youll': 502,\n",
       " 'there': 503,\n",
       " 'teach': 504,\n",
       " 'save': 505,\n",
       " 'remember': 506,\n",
       " 'story': 507,\n",
       " 'many': 508,\n",
       " 'milo': 509,\n",
       " 'attack': 510,\n",
       " 'adoption': 511,\n",
       " 'peanut': 512,\n",
       " 'stray': 513,\n",
       " 'fly': 514,\n",
       " 'daycare': 515,\n",
       " 'mad': 516,\n",
       " 'labrador': 517,\n",
       " 'groom': 518,\n",
       " 'white': 519,\n",
       " 'wonderful': 520,\n",
       " 'instagram': 521,\n",
       " 'fluff': 522,\n",
       " 'fell': 523,\n",
       " 'tucker': 524,\n",
       " 'hide': 525,\n",
       " 'okay': 526,\n",
       " 'heeler': 527,\n",
       " 'mountain': 528,\n",
       " 'welcome': 529,\n",
       " 'cake': 530,\n",
       " 'ellie': 531,\n",
       " 'hug': 532,\n",
       " 'afternoon': 533,\n",
       " 'cancer': 534,\n",
       " 'comfortable': 535,\n",
       " 'shepard': 536,\n",
       " 'curious': 537,\n",
       " 'believe': 538,\n",
       " 'hell': 539,\n",
       " 'spring': 540,\n",
       " 'costume': 541,\n",
       " 'goofy': 542,\n",
       " 'quarantine': 543,\n",
       " 'wild': 544,\n",
       " 'grass': 545,\n",
       " 'lap': 546,\n",
       " 'gorgeous': 547,\n",
       " 'grandma': 548,\n",
       " 'mother': 549,\n",
       " 'lily': 550,\n",
       " 'beauty': 551,\n",
       " 'daddy': 552,\n",
       " 'drink': 553,\n",
       " 'happen': 554,\n",
       " 'lie': 555,\n",
       " 'sunset': 556,\n",
       " 'nd': 557,\n",
       " 'cheese': 558,\n",
       " 'table': 559,\n",
       " 'le': 560,\n",
       " 'boye': 561,\n",
       " 'high': 562,\n",
       " 'poodle': 563,\n",
       " 'fresh': 564,\n",
       " 'tv': 565,\n",
       " 'test': 566,\n",
       " 'odin': 567,\n",
       " 'river': 568,\n",
       " 'mind': 569,\n",
       " 'louie': 570,\n",
       " 'roll': 571,\n",
       " 'wasnt': 572,\n",
       " 'view': 573,\n",
       " 'late': 574,\n",
       " 'stand': 575,\n",
       " 'rosie': 576,\n",
       " 'santa': 577,\n",
       " 'drop': 578,\n",
       " 'position': 579,\n",
       " 'leaf': 580,\n",
       " 'dane': 581,\n",
       " 'door': 582,\n",
       " 'safe': 583,\n",
       " 'tomorrow': 584,\n",
       " 'spaniel': 585,\n",
       " 'dream': 586,\n",
       " 'weve': 587,\n",
       " 'local': 588,\n",
       " 'rough': 589,\n",
       " 'mood': 590,\n",
       " 'aka': 591,\n",
       " 'mommy': 592,\n",
       " 'bird': 593,\n",
       " 'do': 594,\n",
       " 'guard': 595,\n",
       " 'finish': 596,\n",
       " 'ğŸ¤£': 597,\n",
       " 'daily': 598,\n",
       " 'must': 599,\n",
       " 'young': 600,\n",
       " 'autumn': 601,\n",
       " 'sunny': 602,\n",
       " 'mode': 603,\n",
       " 'interest': 604,\n",
       " 'neighbor': 605,\n",
       " 'apparently': 606,\n",
       " 'change': 607,\n",
       " 'window': 608,\n",
       " 'husband': 609,\n",
       " 'teeth': 610,\n",
       " 'scratch': 611,\n",
       " 'patiently': 612,\n",
       " 'seat': 613,\n",
       " 'duke': 614,\n",
       " 'loki': 615,\n",
       " 'tennis': 616,\n",
       " 'blep': 617,\n",
       " 'sock': 618,\n",
       " 'doodle': 619,\n",
       " 'inside': 620,\n",
       " 'shadow': 621,\n",
       " 'pool': 622,\n",
       " 'celebrate': 623,\n",
       " 'penny': 624,\n",
       " 'merry': 625,\n",
       " 'cuteness': 626,\n",
       " 'â™¥ï¸': 627,\n",
       " 'english': 628,\n",
       " 'g': 629,\n",
       " 'mutt': 630,\n",
       " 'tuck': 631,\n",
       " 'precious': 632,\n",
       " 'realize': 633,\n",
       " 'mo': 634,\n",
       " 'cut': 635,\n",
       " 'furry': 636,\n",
       " 'easter': 637,\n",
       " 'sub': 638,\n",
       " 'alone': 639,\n",
       " 'early': 640,\n",
       " 'senior': 641,\n",
       " 'tough': 642,\n",
       " 'bandana': 643,\n",
       " 'arm': 644,\n",
       " 'season': 645,\n",
       " 'extra': 646,\n",
       " 'win': 647,\n",
       " 'lola': 648,\n",
       " 'yall': 649,\n",
       " 'choose': 650,\n",
       " 'different': 651,\n",
       " 'hate': 652,\n",
       " 'garden': 653,\n",
       " 'easy': 654,\n",
       " 'finn': 655,\n",
       " 'sophie': 656,\n",
       " 'winston': 657,\n",
       " 'chew': 658,\n",
       " 'willow': 659,\n",
       " 'close': 660,\n",
       " 'gentleman': 661,\n",
       " 'present': 662,\n",
       " 'bully': 663,\n",
       " 'e': 664,\n",
       " 'near': 665,\n",
       " 'floof': 666,\n",
       " 'step': 667,\n",
       " 'comfy': 668,\n",
       " 'friday': 669,\n",
       " 'pack': 670,\n",
       " 'drive': 671,\n",
       " 'actually': 672,\n",
       " 'talk': 673,\n",
       " 'sad': 674,\n",
       " 'p': 675,\n",
       " 'murphy': 676,\n",
       " 'lick': 677,\n",
       " 'mate': 678,\n",
       " 'olive': 679,\n",
       " 'room': 680,\n",
       " 'sunbathe': 681,\n",
       " 'healthy': 682,\n",
       " 'boyfriend': 683,\n",
       " 'sick': 684,\n",
       " 'shop': 685,\n",
       " 'awesome': 686,\n",
       " 'inu': 687,\n",
       " 'four': 688,\n",
       " 'moose': 689,\n",
       " 'spirit': 690,\n",
       " 'bull': 691,\n",
       " 'least': 692,\n",
       " 'pit': 693,\n",
       " 'collar': 694,\n",
       " 'sand': 695,\n",
       " 'ruff': 696,\n",
       " 'yawn': 697,\n",
       " 'party': 698,\n",
       " 'girlfriend': 699,\n",
       " 'rock': 700,\n",
       " 'butter': 701,\n",
       " 'laundry': 702,\n",
       " 'doggie': 703,\n",
       " 'joy': 704,\n",
       " 'mid': 705,\n",
       " 'coco': 706,\n",
       " 'fight': 707,\n",
       " 'shed': 708,\n",
       " 'service': 709,\n",
       " 'ice': 710,\n",
       " 'riley': 711,\n",
       " 'dress': 712,\n",
       " 'comfort': 713,\n",
       " 'tree': 714,\n",
       " 'act': 715,\n",
       " 'due': 716,\n",
       " 'skin': 717,\n",
       " 'backyard': 718,\n",
       " 'rocky': 719,\n",
       " 'koda': 720,\n",
       " 'el': 721,\n",
       " 'instead': 722,\n",
       " 'result': 723,\n",
       " 'dna': 724,\n",
       " 'regal': 725,\n",
       " 'middle': 726,\n",
       " 'laugh': 727,\n",
       " 'honey': 728,\n",
       " 'peace': 729,\n",
       " 'playtime': 730,\n",
       " 'normal': 731,\n",
       " 'clean': 732,\n",
       " 'groomer': 733,\n",
       " 'smart': 734,\n",
       " 'kitchen': 735,\n",
       " 'company': 736,\n",
       " 'size': 737,\n",
       " 'sam': 738,\n",
       " 'w': 739,\n",
       " 'fellow': 740,\n",
       " 'worry': 741,\n",
       " 'breakfast': 742,\n",
       " 'tear': 743,\n",
       " 'video': 744,\n",
       " 'sorry': 745,\n",
       " 'happiness': 746,\n",
       " 'natural': 747,\n",
       " 'bunny': 748,\n",
       " 'bark': 749,\n",
       " 'smiley': 750,\n",
       " 'serious': 751,\n",
       " 'everyday': 752,\n",
       " 'apollo': 753,\n",
       " 'sky': 754,\n",
       " 'chair': 755,\n",
       " 'wet': 756,\n",
       " 'coat': 757,\n",
       " 'five': 758,\n",
       " 'fine': 759,\n",
       " 'maybe': 760,\n",
       " 'wolf': 761,\n",
       " 'word': 762,\n",
       " 'refuse': 763,\n",
       " 'goofball': 764,\n",
       " 'pizza': 765,\n",
       " 'pomeranian': 766,\n",
       " 'school': 767,\n",
       " 'heckin': 768,\n",
       " 'pyrenees': 769,\n",
       " 'copper': 770,\n",
       " 'absolutely': 771,\n",
       " 'round': 772,\n",
       " 'swear': 773,\n",
       " 'cookie': 774,\n",
       " 'abandon': 775,\n",
       " 'bee': 776,\n",
       " 'begin': 777,\n",
       " 'join': 778,\n",
       " 'anxiety': 779,\n",
       " 'rat': 780,\n",
       " 'identify': 781,\n",
       " 'city': 782,\n",
       " 'pitbull': 783,\n",
       " 'stuff': 784,\n",
       " 'energy': 785,\n",
       " 'stella': 786,\n",
       " 'zoey': 787,\n",
       " 'bean': 788,\n",
       " 'discover': 789,\n",
       " 'imagine': 790,\n",
       " 'gu': 791,\n",
       " 'snack': 792,\n",
       " 'sweater': 793,\n",
       " 'chocolate': 794,\n",
       " 'explore': 795,\n",
       " 'nature': 796,\n",
       " 'greet': 797,\n",
       " 'rottweiler': 798,\n",
       " 'throw': 799,\n",
       " 'vibe': 800,\n",
       " 'aunt': 801,\n",
       " 'pal': 802,\n",
       " 'trail': 803,\n",
       " 'reaction': 804,\n",
       " 'elsa': 805,\n",
       " 'ruby': 806,\n",
       " 'destroy': 807,\n",
       " 'innocent': 808,\n",
       " 'along': 809,\n",
       " 'piper': 810,\n",
       " 'truly': 811,\n",
       " 'wood': 812,\n",
       " 'french': 813,\n",
       " 'rare': 814,\n",
       " 'zeus': 815,\n",
       " 'cause': 816,\n",
       " 'gracie': 817,\n",
       " 'felt': 818,\n",
       " 'usually': 819,\n",
       " 'pig': 820,\n",
       " 'weird': 821,\n",
       " 'l': 822,\n",
       " 'beloved': 823,\n",
       " 'able': 824,\n",
       " 'blind': 825,\n",
       " 'woof': 826,\n",
       " 'probably': 827,\n",
       " 'jake': 828,\n",
       " 'bday': 829,\n",
       " 'nephew': 830,\n",
       " 'behind': 831,\n",
       " 'learn': 832,\n",
       " 'mile': 833,\n",
       " 'farm': 834,\n",
       " 'wind': 835,\n",
       " 'thanksgiving': 836,\n",
       " 'surprise': 837,\n",
       " 'group': 838,\n",
       " 'heaven': 839,\n",
       " 'oliver': 840,\n",
       " 'anymore': 841,\n",
       " 'perfectly': 842,\n",
       " 'frisbee': 843,\n",
       " 'winnie': 844,\n",
       " 'beat': 845,\n",
       " 'quiet': 846,\n",
       " 'leo': 847,\n",
       " 'loyal': 848,\n",
       " 'hoomans': 849,\n",
       " 'consider': 850,\n",
       " 'listen': 851,\n",
       " 'n': 852,\n",
       " 'dirt': 853,\n",
       " 'soul': 854,\n",
       " 'forest': 855,\n",
       " 'unexpectedly': 856,\n",
       " 'selfie': 857,\n",
       " 'san': 858,\n",
       " 'yoda': 859,\n",
       " 'jax': 860,\n",
       " 'goldendoodle': 861,\n",
       " 'suggestion': 862,\n",
       " 'rug': 863,\n",
       " 'hungry': 864,\n",
       " 'nala': 865,\n",
       " 'therapy': 866,\n",
       " 'dig': 867,\n",
       " 'bestest': 868,\n",
       " 'sully': 869,\n",
       " 'tie': 870,\n",
       " 'master': 871,\n",
       " 'charles': 872,\n",
       " 'read': 873,\n",
       " 'mum': 874,\n",
       " 'mama': 875,\n",
       " 'carry': 876,\n",
       " 'others': 877,\n",
       " 'focus': 878,\n",
       " 'stanley': 879,\n",
       " 'addition': 880,\n",
       " 'millie': 881,\n",
       " 'haha': 882,\n",
       " 'fox': 883,\n",
       " 'pls': 884,\n",
       " 'double': 885,\n",
       " 'whenever': 886,\n",
       " 'bonnie': 887,\n",
       " 'shih': 888,\n",
       " 'chance': 889,\n",
       " 'gentle': 890,\n",
       " 'hasnt': 891,\n",
       " 'ava': 892,\n",
       " 'dogo': 893,\n",
       " 'single': 894,\n",
       " 'â¤ï¸â¤ï¸': 895,\n",
       " 'ghost': 896,\n",
       " 'touch': 897,\n",
       " 'taco': 898,\n",
       " 'sofa': 899,\n",
       " 'havent': 900,\n",
       " 'link': 901,\n",
       " 'deep': 902,\n",
       " 'bathroom': 903,\n",
       " 'doge': 904,\n",
       " 'grind': 905,\n",
       " 'chicken': 906,\n",
       " 'remind': 907,\n",
       " 'lucky': 908,\n",
       " 'litter': 909,\n",
       " 'tuesday': 910,\n",
       " 'biscuit': 911,\n",
       " 'patch': 912,\n",
       " 'space': 913,\n",
       " 'companion': 914,\n",
       " 'shit': 915,\n",
       " 'harness': 916,\n",
       " 'neighborhood': 917,\n",
       " 'deserve': 918,\n",
       " 'ollie': 919,\n",
       " 'pooch': 920,\n",
       " 'important': 921,\n",
       " 'soft': 922,\n",
       " 'longer': 923,\n",
       " 'butt': 924,\n",
       " 'album': 925,\n",
       " 'health': 926,\n",
       " 'breath': 927,\n",
       " 'obsess': 928,\n",
       " 'ğŸ–¤': 929,\n",
       " 'clear': 930,\n",
       " 'daughter': 931,\n",
       " 'ğŸ•': 932,\n",
       " 'walter': 933,\n",
       " 'introduce': 934,\n",
       " 'shower': 935,\n",
       " 'pee': 936,\n",
       " 'blow': 937,\n",
       " 'stare': 938,\n",
       " 'wag': 939,\n",
       " 'harvey': 940,\n",
       " 'update': 941,\n",
       " 'war': 942,\n",
       " 'pom': 943,\n",
       " 'harley': 944,\n",
       " 'playful': 945,\n",
       " 'goof': 946,\n",
       " 'chewie': 947,\n",
       " 'style': 948,\n",
       " 'bat': 949,\n",
       " 'cheer': 950,\n",
       " 'color': 951,\n",
       " 'neck': 952,\n",
       " 'dirty': 953,\n",
       " 'xpost': 954,\n",
       " 'scary': 955,\n",
       " 'beast': 956,\n",
       " 'meme': 957,\n",
       " 'bow': 958,\n",
       " 'impress': 959,\n",
       " 'study': 960,\n",
       " 'sausage': 961,\n",
       " 'catahoula': 962,\n",
       " 'approve': 963,\n",
       " 'bigger': 964,\n",
       " 'bless': 965,\n",
       " 'deaf': 966,\n",
       " 'unicorn': 967,\n",
       " 'boops': 968,\n",
       " 'everywhere': 969,\n",
       " 'hoodie': 970,\n",
       " 'set': 971,\n",
       " 'snowy': 972,\n",
       " 'piece': 973,\n",
       " 'kennel': 974,\n",
       " 'judge': 975,\n",
       " 'cousin': 976,\n",
       " 'monster': 977,\n",
       " 'case': 978,\n",
       " 'ray': 979,\n",
       " 'upset': 980,\n",
       " 'fancy': 981,\n",
       " 'protect': 982,\n",
       " 'shy': 983,\n",
       " 'boat': 984,\n",
       " 'walkies': 985,\n",
       " 'bag': 986,\n",
       " 'demand': 987,\n",
       " 'search': 988,\n",
       " 'roommate': 989,\n",
       " 'entire': 990,\n",
       " 'action': 991,\n",
       " 'oscar': 992,\n",
       " 'print': 993,\n",
       " 'colorado': 994,\n",
       " 'tzu': 995,\n",
       " 'hop': 996,\n",
       " 'gold': 997,\n",
       " 'bug': 998,\n",
       " 'chloe': 999,\n",
       " 'fan': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Whole Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['basic_cleaning'] = data.title.apply(expand_contractions)\n",
    "\n",
    "data['basic_cleaning'] = data.basic_cleaning.apply(basic_cleaning)\n",
    "\n",
    "data['no_stopword'] = data['basic_cleaning'].apply(remove_stopwords)\n",
    "\n",
    "data['no_stopword'] = data.no_stopword.apply(word_tokenize)\n",
    "\n",
    "data['lemmatize'] = data['no_stopword'].apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      [cute, little, baby]\n",
       "1         [myboytonka, bluestaffy, familypet, enjoy, wal...\n",
       "2         [bennington, say, he, basset, pitt, catahoula,...\n",
       "3         [dog, pretty, much, color, whats, leave, morni...\n",
       "4                        [happy, malinois, name, han, solo]\n",
       "                                ...                        \n",
       "151893                       [unbearable, cuteness, stella]\n",
       "151894                       [lexi, day, bring, home, spca]\n",
       "151895                                  [something, stella]\n",
       "151896                                 [dog, wear, doggles]\n",
       "151897                                              [sadie]\n",
       "Name: lemmatize, Length: 151898, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vector (Alternative to tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Pre-trained model glove-twitter-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rd/q2lzfdss4b167026m7l6h8pm0000gn/T/ipykernel_90915/3197301852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mglove_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove-twitter-25'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mglove_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'twitter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gensim-data/glove-twitter-25/__init__.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-twitter-25'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-twitter-25.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \"\"\"\n\u001b[0;32m-> 1629\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             )\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0m_word2vec_read_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_text\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1877\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline_no\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1879\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1880\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "print(list(gensim.downloader.info()['models'].keys()))\n",
    "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
    "glove_vectors.most_similar('twitter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My model of whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "vec_size = 20\n",
    "word2vec = Word2Vec(sentences=data['lemmatize'], vector_size=vec_size, min_count=10, window=4)\n",
    "# how to select vector_size? might be too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1888a8fd0>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec # trained base on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.3517152 , -1.9031105 ,  0.39014116,  0.4409856 , -1.2348068 ,\n",
       "       -1.8261825 , -0.50980526,  0.9770071 ,  1.3244848 , -1.2770796 ,\n",
       "        0.35140288,  0.46993938, -0.05866685, -1.103844  , -0.7304762 ,\n",
       "        0.0809565 ,  0.12632218, -1.1952039 , -1.0516698 , -0.28064433],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('animal', 0.7748593688011169),\n",
       " ('pup', 0.7626678347587585),\n",
       " ('doggo', 0.7018442153930664),\n",
       " ('doggy', 0.6958211660385132),\n",
       " ('also', 0.6898082494735718),\n",
       " ('place', 0.684063732624054),\n",
       " ('kid', 0.6815078258514404),\n",
       " ('doggos', 0.6798000931739807),\n",
       " ('puppers', 0.6708903312683105),\n",
       " ('person', 0.6566869616508484),\n",
       " ('probably', 0.6530404090881348),\n",
       " ('own', 0.6477996110916138),\n",
       " ('theyre', 0.6432768702507019),\n",
       " ('puppy', 0.6416468620300293),\n",
       " ('one', 0.6403688192367554)]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar('dog', topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Pre-trained model 'glove-twitter-200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rd/q2lzfdss4b167026m7l6h8pm0000gn/T/ipykernel_99011/2811194963.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtwitter200_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove-twitter-200'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtwitter200_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'twitter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gensim-data/glove-twitter-200/__init__.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-twitter-200'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove-twitter-200.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \"\"\"\n\u001b[0;32m-> 1629\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             )\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0m_word2vec_read_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_text\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1879\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m         \u001b[0m_add_word_to_kv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_line_to_vector\u001b[0;34m(line, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1887\u001b[0;31m     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1888\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1887\u001b[0;31m     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1888\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "twitter200_corpus = api.load('glove-twitter-200')\n",
    "twitter200_corpus.most_similar('twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twitter200_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rd/q2lzfdss4b167026m7l6h8pm0000gn/T/ipykernel_90915/2832956461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtwitter200_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'leaf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'twitter200_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "twitter200_corpus.similarity('tree', 'leaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.8483485579490662),\n",
       " ('cat', 0.832430362701416),\n",
       " ('puppy', 0.7890411019325256),\n",
       " ('pet', 0.7524258494377136),\n",
       " ('cats', 0.7141677141189575),\n",
       " ('horse', 0.6632055640220642),\n",
       " ('animal', 0.657815158367157),\n",
       " ('kitten', 0.6441184878349304),\n",
       " ('little', 0.632893979549408),\n",
       " ('kid', 0.6253357529640198)]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter200_corpus.most_similar('dog', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "example = ['this', 'movie', 'is', 'the', 'worst', 'action', 'movie', 'ever']\n",
    "example_missing_words = ['this', 'movie', 'is', 'laaaaaaaaaame']\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    wv = word2vec.wv\n",
    "    to_array = []\n",
    "#     print(sentence)\n",
    "    for word in sentence:\n",
    "        if word in wv.key_to_index:\n",
    "            to_array.append(wv[word])\n",
    "    return np.array(to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embedding'] = df['lemmatize'].apply(lambda x: embed_sentence(word2vec,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72359</th>\n",
       "      <td>[[0.8587935, -0.5100097, -0.6470577, -0.542312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117238</th>\n",
       "      <td>[[-0.8953133, -0.9158622, -0.63884795, -0.1204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74310</th>\n",
       "      <td>[[0.16461626, 0.32013926, 0.009713764, 0.18614...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110206</th>\n",
       "      <td>[[0.4197325, 1.005667, 0.22347336, -1.0603021,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49964</th>\n",
       "      <td>[[-0.017749067, -0.13825125, -0.15346892, 0.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32080</th>\n",
       "      <td>[[-0.90217334, -0.38298208, -0.031965636, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>[[-0.08284962, 0.005258159, 0.34169534, 0.3595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121554</th>\n",
       "      <td>[[-1.8096888, -1.441027, -1.5824249, 0.1120013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43425</th>\n",
       "      <td>[[-0.14885898, 0.051192172, -0.24123818, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133671</th>\n",
       "      <td>[[-0.5105188, -0.4463094, -0.80707484, -1.3576...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                embedding\n",
       "72359   [[0.8587935, -0.5100097, -0.6470577, -0.542312...\n",
       "117238  [[-0.8953133, -0.9158622, -0.63884795, -0.1204...\n",
       "74310   [[0.16461626, 0.32013926, 0.009713764, 0.18614...\n",
       "110206  [[0.4197325, 1.005667, 0.22347336, -1.0603021,...\n",
       "49964   [[-0.017749067, -0.13825125, -0.15346892, 0.29...\n",
       "...                                                   ...\n",
       "32080   [[-0.90217334, -0.38298208, -0.031965636, -0.0...\n",
       "6865    [[-0.08284962, 0.005258159, 0.34169534, 0.3595...\n",
       "121554  [[-1.8096888, -1.441027, -1.5824249, 0.1120013...\n",
       "43425   [[-0.14885898, 0.051192172, -0.24123818, -0.00...\n",
       "133671  [[-0.5105188, -0.4463094, -0.80707484, -1.3576...\n",
       "\n",
       "[30000 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['embedding']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_length = 15\n",
    "X_train = pad_sequences(df['embedding'], dtype='float32', padding='post', value=-1000,maxlen=max_length)\n",
    "# padding with [0., 0., 0., .......]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 15, 20)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combine Model for py. file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_punc = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~â€œâ€â€™'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(text,word2vec=word2vec,contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    # 1. Expand Contractions\n",
    "    \"\"\"Expand the contractions in English. e.g. I'm ==> I am\"\"\"\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    \n",
    "    # 2. Basic Cleaning\n",
    "    sentence = expanded_text.lower()\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    for punctuation in my_punc:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 2. Remove Stopwords\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    remove_s = \" \".join([word for word in str(sentence).split() if word not in STOPWORDS])\n",
    "    \n",
    "    # 3. Word Tokenize\n",
    "    word_tokens = word_tokenize(remove_s)\n",
    "    \n",
    "    # 4. Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_n = [lemmatizer.lemmatize(word,pos='n') for word in word_tokens]\n",
    "    lemmatized_v = [lemmatizer.lemmatize(word,pos='v') for word in lemmatized_n] \n",
    "    \n",
    "    # 5. Embedding\n",
    "    wv = word2vec.wv\n",
    "    to_array = []    \n",
    "    for word in lemmatized_v:\n",
    "        if word in wv.key_to_index:\n",
    "            to_array.append(wv[word])\n",
    "    return np.array(to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_embedding = df['title'].apply(lambda sentence: preprocessing(sentence,word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_embedding, dtype='float32', padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the Binary Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cat_upvotes(original_df, threshold=50):\n",
    "    \"\"\"\n",
    "    Takes column from df called 'upvotes' and returns df with new column\n",
    "    'cat_upvotes' which is 1 if upvotes is above threshold, and 0 otherwise.\n",
    "    \"\"\"\n",
    "    dataframe = original_df.copy()\n",
    "    if 'upvotes' not in original_df.columns:\n",
    "        raise ValueError(\"df has no column named 'upvotes'\")\n",
    "    def trans(number):\n",
    "        if number >= threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    dataframe['cat_upvotes'] = dataframe['upvotes'].apply(trans)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna().sample(20000,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = binary_cat_upvotes(df, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['basic_cleaning'] = df.title.apply(basic_cleaning)\n",
    "\n",
    "df['no_stopword'] = df['basic_cleaning'].apply(remove_stopwords)\n",
    "\n",
    "df['no_stopword'] = df.no_stopword.apply(word_tokenize)\n",
    "\n",
    "df['lemmatize'] = df['no_stopword'].apply(lemma)\n",
    "\n",
    "df['embedding'] = df['lemmatize'].apply(lambda x: embed_sentence(word2vec,x))\n",
    "\n",
    "# df['padding'] = pad_sequences(df['embedding'], dtype='float32', padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(df['embedding'], dtype='float32', padding='post', maxlen=max_length,value=-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cat_upvotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>title_len</th>\n",
       "      <th>cat_upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17997.000000</td>\n",
       "      <td>1.799700e+04</td>\n",
       "      <td>17997.00000</td>\n",
       "      <td>17997.000000</td>\n",
       "      <td>17997.000000</td>\n",
       "      <td>17997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>76783.757571</td>\n",
       "      <td>1.583589e+09</td>\n",
       "      <td>0.93701</td>\n",
       "      <td>16.551814</td>\n",
       "      <td>8.304551</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43663.055107</td>\n",
       "      <td>5.138741e+07</td>\n",
       "      <td>0.08889</td>\n",
       "      <td>20.781138</td>\n",
       "      <td>7.591897</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.271672e+09</td>\n",
       "      <td>0.11000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38860.000000</td>\n",
       "      <td>1.543619e+09</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>77718.000000</td>\n",
       "      <td>1.584039e+09</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>114456.000000</td>\n",
       "      <td>1.627469e+09</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151895.000000</td>\n",
       "      <td>1.668689e+09</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0    time_stamp  upvote_ratio       upvotes     title_len  \\\n",
       "count   17997.000000  1.799700e+04   17997.00000  17997.000000  17997.000000   \n",
       "mean    76783.757571  1.583589e+09       0.93701     16.551814      8.304551   \n",
       "std     43663.055107  5.138741e+07       0.08889     20.781138      7.591897   \n",
       "min         0.000000  1.271672e+09       0.11000      0.000000      1.000000   \n",
       "25%     38860.000000  1.543619e+09       0.90000      1.000000      3.000000   \n",
       "50%     77718.000000  1.584039e+09       0.97000      9.000000      6.000000   \n",
       "75%    114456.000000  1.627469e+09       1.00000     21.000000     10.000000   \n",
       "max    151895.000000  1.668689e+09       1.00000    109.000000     67.000000   \n",
       "\n",
       "       cat_upvotes  \n",
       "count      17997.0  \n",
       "mean           0.0  \n",
       "std            0.0  \n",
       "min            0.0  \n",
       "25%            0.0  \n",
       "50%            0.0  \n",
       "75%            0.0  \n",
       "max            0.0  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.cat_upvotes==0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0-1, 2-30, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10     1.0\n",
       "0.20     1.0\n",
       "0.25     2.0\n",
       "0.50    11.0\n",
       "0.60    16.0\n",
       "0.75    30.0\n",
       "0.85    62.0\n",
       "Name: upvotes, dtype: float64"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.upvotes.quantile([0.1,0.2,0.25,0.5,0.6,0.75,0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>title_len</th>\n",
       "      <th>cat_upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>76091.404650</td>\n",
       "      <td>1.584404e+09</td>\n",
       "      <td>0.942166</td>\n",
       "      <td>94.114200</td>\n",
       "      <td>8.557500</td>\n",
       "      <td>0.426550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43807.699893</td>\n",
       "      <td>5.138389e+07</td>\n",
       "      <td>0.085852</td>\n",
       "      <td>553.474625</td>\n",
       "      <td>7.824197</td>\n",
       "      <td>0.494588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.271672e+09</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37964.750000</td>\n",
       "      <td>1.544237e+09</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76717.000000</td>\n",
       "      <td>1.585114e+09</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>114019.500000</td>\n",
       "      <td>1.628408e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151895.000000</td>\n",
       "      <td>1.668689e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34572.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0    time_stamp  upvote_ratio       upvotes     title_len  \\\n",
       "count   20000.000000  2.000000e+04  20000.000000  20000.000000  20000.000000   \n",
       "mean    76091.404650  1.584404e+09      0.942166     94.114200      8.557500   \n",
       "std     43807.699893  5.138389e+07      0.085852    553.474625      7.824197   \n",
       "min         0.000000  1.271672e+09      0.110000      0.000000      1.000000   \n",
       "25%     37964.750000  1.544237e+09      0.910000      2.000000      4.000000   \n",
       "50%     76717.000000  1.585114e+09      0.980000     11.000000      6.000000   \n",
       "75%    114019.500000  1.628408e+09      1.000000     30.000000     11.000000   \n",
       "max    151895.000000  1.668689e+09      1.000000  34572.000000     67.000000   \n",
       "\n",
       "        cat_upvotes  \n",
       "count  20000.000000  \n",
       "mean       0.426550  \n",
       "std        0.494588  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57345"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 1 - 0.426550\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.upvotes.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_upvotes = np.log(df.upvotes+1)\n",
    "log_upvotes[log_upvotes < 3].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upvotes\n",
       "0         124\n",
       "1        4402\n",
       "2         617\n",
       "3         557\n",
       "4         453\n",
       "         ... \n",
       "14966       1\n",
       "15472       1\n",
       "17905       1\n",
       "18806       1\n",
       "34572       1\n",
       "Name: upvotes, Length: 1046, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('upvotes')['upvotes'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQYklEQVR4nO3df4hd5Z3H8fe3RmtrWKNVBjcJO4KhJVVa7aB2hWXUrUYtjX9Ysbg2Spb8Y3ftItRYKLKtQgpSa6EVgmabdsVUrItBZd0QHaR/+Cva9VdWnPVnsta0TUw7trWb9rt/3GeGS3YmczNzf8193i8Y7jnP+XGfL5N8zrnPOfdMZCaSpDp8qNcdkCR1j6EvSRUx9CWpIoa+JFXE0JekiizqdQcO5YQTTsjh4eE5b//+++9zzDHHtK9Dfco6B0stdUI9tXa7zh07dvwqM0+cbllfh/7w8DDPPPPMnLcfGxtjdHS0fR3qU9Y5WGqpE+qptdt1RsSbMy1zeEeSKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkirS19/I7RfD6x+amn5jwyU97IkkzY9n+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIi2HfkQcERHPRcSDZf7kiHgyIsYj4icRcVRp/3CZHy/Lh5v2cWNpfyUiLmx7NZKkQzqcM/3rgJ1N898GbsvMU4B9wNrSvhbYV9pvK+sRESuBK4BPAquAH0TEEfPrviTpcLQU+hGxDLgEuLPMB3AecF9ZZTNwaZleXeYpy88v668GtmTmB5n5OjAOnNmGGiRJLWr1TP+7wNeAP5f5jwHvZeaBMr8LWFqmlwJvA5Tl+8v6U+3TbCNJ6oJZ/1xiRHwe2JOZOyJitNMdioh1wDqAoaEhxsbG5ryviYmJeW0/6frTDkxNt2N/7dauOvuddQ6eWmrtpzpb+Ru55wBfiIiLgaOBvwBuB5ZExKJyNr8M2F3W3w0sB3ZFxCLgWODXTe2TmreZkpkbgY0AIyMjOTo6OoeyGsbGxpjP9pOubv4buVfOf3/t1q46+511Dp5aau2nOmcd3snMGzNzWWYO07gQ+2hmXgk8BlxWVlsDPFCmt5Z5yvJHMzNL+xXl7p6TgRXAU22rRJI0q1bO9GdyA7AlIm4GngPuKu13AT+OiHFgL40DBZn5UkTcC7wMHACuzcw/zeP9JUmH6bBCPzPHgLEy/RrT3H2TmX8AvjjD9rcAtxxuJyVJ7eE3ciWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SarIrKEfEUdHxFMR8Z8R8VJE/HNpPzkinoyI8Yj4SUQcVdo/XObHy/Lhpn3dWNpfiYgLO1aVJGlarZzpfwCcl5mfAj4NrIqIs4FvA7dl5inAPmBtWX8tsK+031bWIyJWAlcAnwRWAT+IiCPaWIskaRazhn42TJTZI8tPAucB95X2zcClZXp1macsPz8iorRvycwPMvN1YBw4sx1FSJJas6iVlcoZ+Q7gFOD7wH8D72XmgbLKLmBpmV4KvA2QmQciYj/wsdL+RNNum7dpfq91wDqAoaEhxsbGDq+iJhMTE/PaftL1px2Ymm7H/tqtXXX2O+scPLXU2k91thT6mfkn4NMRsQT4N+ATnepQZm4ENgKMjIzk6OjonPc1NjbGfLafdPX6h6am37hy/vtrt3bV2e+sc/DUUms/1XlYd+9k5nvAY8BngSURMXnQWAbsLtO7geUAZfmxwK+b26fZRpLUBa3cvXNiOcMnIj4CfA7YSSP8LyurrQEeKNNbyzxl+aOZmaX9inJ3z8nACuCpNtUhSWpBK8M7JwGby7j+h4B7M/PBiHgZ2BIRNwPPAXeV9e8CfhwR48BeGnfskJkvRcS9wMvAAeDaMmwkSeqSWUM/M58HTp+m/TWmufsmM/8AfHGGfd0C3HL43ZQktYPfyJWkihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFZk19CNieUQ8FhEvR8RLEXFdaT8+IrZFxKvl9bjSHhHxvYgYj4jnI+KMpn2tKeu/GhFrOleWJGk6rZzpHwCuz8yVwNnAtRGxElgPbM/MFcD2Mg9wEbCi/KwD7oDGQQK4CTgLOBO4afJAIUnqjllDPzPfycxny/RvgZ3AUmA1sLmsthm4tEyvBn6UDU8ASyLiJOBCYFtm7s3MfcA2YFU7i5EkHVpkZusrRwwDjwOnAm9l5pLSHsC+zFwSEQ8CGzLzZ2XZduAGYBQ4OjNvLu3fAH6fmbce9B7raHxCYGho6DNbtmyZc3ETExMsXrx4zttPemH3/qnp05YeO+/9tVu76ux31jl4aqm123Wee+65OzJzZLpli1rdSUQsBn4KfDUzf9PI+YbMzIho/ehxCJm5EdgIMDIykqOjo3Pe19jYGPPZftLV6x+amn7jyvnvr93aVWe/s87BU0ut/VRnS3fvRMSRNAL/7sy8vzS/W4ZtKK97SvtuYHnT5stK20ztkqQuaeXunQDuAnZm5neaFm0FJu/AWQM80NT+5XIXz9nA/sx8B3gEuCAijisXcC8obZKkLmlleOcc4CrghYj4eWn7OrABuDci1gJvApeXZQ8DFwPjwO+AawAyc29EfAt4uqz3zczc244iJEmtmTX0ywXZmGHx+dOsn8C1M+xrE7DpcDooSWofv5ErSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUkUW97oC6Y3j9Q1PTb2y4pIc9kdRLs57pR8SmiNgTES82tR0fEdsi4tXyelxpj4j4XkSMR8TzEXFG0zZryvqvRsSazpQjSTqUVoZ3fgisOqhtPbA9M1cA28s8wEXAivKzDrgDGgcJ4CbgLOBM4KbJA4UkqXtmDf3MfBzYe1DzamBzmd4MXNrU/qNseAJYEhEnARcC2zJzb2buA7bx/w8kkqQOi8ycfaWIYeDBzDy1zL+XmUvKdAD7MnNJRDwIbMjMn5Vl24EbgFHg6My8ubR/A/h9Zt46zXuto/EpgaGhoc9s2bJlzsVNTEywePHiOW8/6YXd+6emT1t67Lz3126t1NnvNbSiXb/PfldLnVBPrd2u89xzz92RmSPTLZv3hdzMzIiY/cjR+v42AhsBRkZGcnR0dM77GhsbYz7bT7q6+SLolfPfX7u1Ume/19CKdv0++10tdUI9tfZTnXO9ZfPdMmxDed1T2ncDy5vWW1baZmqXJHXRXEN/KzB5B84a4IGm9i+Xu3jOBvZn5jvAI8AFEXFcuYB7QWmTJHXRrMM7EXEPjTH5EyJiF427cDYA90bEWuBN4PKy+sPAxcA48DvgGoDM3BsR3wKeLut9MzMPvjgsSeqwWUM/M780w6Lzp1k3gWtn2M8mYNNh9U6S1FZ+I1dT/NauNPh89o4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIn45S7PyS1vS4PBMX5IqYuhLUkUM/Q4YXv/Q1E833uuF3fu78l6SFj7H9BegVgLeg4Ck6Rj6C4QhLqkdDP0eWah3xMzU74Vaj1Qbx/QlqSKe6VfIoSKpXoa+5mymg4dDPVL/MvT7jIEpqZMc05ekinimr2m1a9zfTy5Sf/FMX5IqYuhLUkUc3lFPzDR85BCQ1Fme6UtSRTzTV9f4pTCp9wx99S3v/JHaz+EdSaqIZ/pacPwEIM2doa++cqjn+Vx/2gGu9rqANC+GvhY0b/2UDo9j+pJUEc/0NZD8BCBNz9BXVQ4+GMx0EPBisQbVQIf+C7v3T1348z+upuMXxlSbgQ59qR1aOTB4UqGFwtCX2uBwPzF4kFCvdD30I2IVcDtwBHBnZm7odh+kXjvUQWK27yN4wNB8dDX0I+II4PvA54BdwNMRsTUzX+5mP6SFrF+uQzQffPyks3B0+0z/TGA8M18DiIgtwGrA0JcWmPkcfCa3ncu3rD1gzE9kZvfeLOIyYFVm/n2Zvwo4KzO/0rTOOmBdmf048Mo83vIE4Ffz2H6hsM7BUkudUE+t3a7zrzLzxOkW9N2F3MzcCGxsx74i4pnMHGnHvvqZdQ6WWuqEemrtpzq7/RiG3cDypvllpU2S1AXdDv2ngRURcXJEHAVcAWztch8kqVpdHd7JzAMR8RXgERq3bG7KzJc6+JZtGSZaAKxzsNRSJ9RTa9/U2dULuZKk3vLRypJUEUNfkioykKEfEasi4pWIGI+I9b3uTydExPKIeCwiXo6IlyLiul73qZMi4oiIeC4iHux1XzopIpZExH0R8V8RsTMiPtvrPnVCRPxT+Xf7YkTcExFH97pP7RIRmyJiT0S82NR2fERsi4hXy+txverfwIV+06MeLgJWAl+KiJW97VVHHACuz8yVwNnAtQNa56TrgJ297kQX3A78e2Z+AvgUA1hzRCwF/hEYycxTadzUcUVve9VWPwRWHdS2HtiemSuA7WW+JwYu9Gl61ENm/hGYfNTDQMnMdzLz2TL9WxrhsLS3veqMiFgGXALc2eu+dFJEHAv8DXAXQGb+MTPf62mnOmcR8JGIWAR8FPifHvenbTLzcWDvQc2rgc1lejNwaTf71GwQQ38p8HbT/C4GNAwnRcQwcDrwZI+70infBb4G/LnH/ei0k4FfAv9ShrLujIhjet2pdsvM3cCtwFvAO8D+zPyP3vaq44Yy850y/QtgqFcdGcTQr0pELAZ+Cnw1M3/T6/60W0R8HtiTmTt63ZcuWAScAdyRmacD79PDYYBOKePZq2kc5P4SOCYi/q63veqebNwn37N75Qcx9Kt51ENEHEkj8O/OzPt73Z8OOQf4QkS8QWOo7ryI+NfedqljdgG7MnPyE9t9NA4Cg+Zvgdcz85eZ+b/A/cBf97hPnfZuRJwEUF739Kojgxj6VTzqISKCxtjvzsz8Tq/70ymZeWNmLsvMYRq/y0czcyDPCjPzF8DbEfHx0nQ+g/nY8beAsyPio+Xf8fkM4AXrg2wF1pTpNcADvepI3z1lc7568KiHXjkHuAp4ISJ+Xtq+npkP965LaoN/AO4uJyyvAdf0uD9tl5lPRsR9wLM07kJ7jj56TMF8RcQ9wChwQkTsAm4CNgD3RsRa4E3g8p71z8cwSFI9BnF4R5I0A0Nfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVeT/AEOz7w7jvqIXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(df.upvotes+1).hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Build Dense layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_model = Sequential()\n",
    "d_model.add(layers.Dense(10, input_shape=(max_length,vec_size), activation='relu'))\n",
    "\n",
    "d_model.add(layers.Dense(128, activation='relu'))\n",
    "d_model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Binary output\n",
    "d_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "opt = Adam(\n",
    "learning_rate=0.001 #, beta_1=0.9, beta_2=0.99\n",
    ")\n",
    "\n",
    "d_model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.6747 - accuracy: 0.5906 - val_loss: 0.6751 - val_accuracy: 0.5868\n",
      "Epoch 2/1000\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.6739 - accuracy: 0.5926 - val_loss: 0.6751 - val_accuracy: 0.5872\n",
      "Epoch 3/1000\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.6735 - accuracy: 0.5926 - val_loss: 0.6751 - val_accuracy: 0.5876\n",
      "Epoch 4/1000\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.6736 - accuracy: 0.5918 - val_loss: 0.6748 - val_accuracy: 0.5870\n",
      "Epoch 5/1000\n",
      "1225/1225 [==============================] - 2s 2ms/step - loss: 0.6733 - accuracy: 0.5937 - val_loss: 0.6753 - val_accuracy: 0.5857\n",
      "Epoch 6/1000\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.6732 - accuracy: 0.5931 - val_loss: 0.6759 - val_accuracy: 0.5878\n",
      "Epoch 7/1000\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.6732 - accuracy: 0.5934 - val_loss: 0.6748 - val_accuracy: 0.5873\n",
      "Epoch 8/1000\n",
      "1225/1225 [==============================] - 3s 2ms/step - loss: 0.6732 - accuracy: 0.5941 - val_loss: 0.6749 - val_accuracy: 0.5876\n",
      "Epoch 9/1000\n",
      "1035/1225 [========================>.....] - ETA: 0s - loss: 0.6730 - accuracy: 0.5941"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rd/q2lzfdss4b167026m7l6h8pm0000gn/T/ipykernel_3520/4124437088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = d_model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1210\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1248\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4062\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4064\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   4065\u001b[0m         _ctx, \"Identity\", name, input)\n\u001b[1;32m   4066\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=10, restore_best_weights=False)\n",
    "\n",
    "history = d_model.fit(X_train, y_train,\n",
    "    batch_size=8,\n",
    "    epochs=1000,\n",
    "    validation_split=0.3,\n",
    "    shuffle=True,\n",
    "    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build RNN LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.metrics import Recall, Precision, Accuracy, BinaryAccuracy\n",
    "\n",
    "from tensorflow.keras import regularizers, Sequential, layers\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_model = Sequential()\n",
    "l_model.add(layers.Masking(mask_value=-1000))\n",
    "\n",
    "# initializer = tf.keras.initializers.LecunUniform() #  TruncatedNormal()  ,kernel_initializer=initializer\n",
    "# kernel_regularizer='l1')\n",
    "# initializer = tf.keras.initializers.VarianceScaling(scale=0.1, mode='fan_in', distribution='uniform')\n",
    "\n",
    "l_model.add(layers.LSTM(32, activation = \"tanh\",kernel_regularizer='l1'))\n",
    "l_model.add(layers.Dense(20, activation = \"relu\"))\n",
    "l_model.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.metrics.Accuracy at 0x18a2662b0>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "#     Recall(),\n",
    "    Precision(thresholds=0.38),\n",
    "    BinaryAccuracy(threshold=0.38)\n",
    "#     keras.metrics.AUC(name='prc', curve='PR'),  # precision-recall curve\n",
    "#     keras.metrics.BinaryAccuracy(threshold=0.38)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "\n",
    "# lr_schedule = ExponentialDecay(\n",
    "#     initial_learning_rate=1e-2,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9)\n",
    "# optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "l_model.compile(loss='binary_crossentropy',\n",
    "              optimizer= 'rmsprop', # customize learning rate\n",
    "              metrics= metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57345"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7680\n",
       "0    6320\n",
       "Name: cat_upvotes, dtype: int64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "613/613 [==============================] - 12s 11ms/step - loss: 0.8679 - precision_16: 0.2544 - binary_accuracy: 0.7015 - val_loss: 0.5918 - val_precision_16: 0.4483 - val_binary_accuracy: 0.7331\n",
      "Epoch 2/500\n",
      "613/613 [==============================] - 5s 8ms/step - loss: 0.5775 - precision_16: 0.4414 - binary_accuracy: 0.7435 - val_loss: 0.5946 - val_precision_16: 0.4078 - val_binary_accuracy: 0.7229\n",
      "Epoch 3/500\n",
      "613/613 [==============================] - 5s 9ms/step - loss: 0.5756 - precision_16: 0.4515 - binary_accuracy: 0.7430 - val_loss: 0.5894 - val_precision_16: 0.3962 - val_binary_accuracy: 0.7198\n",
      "Epoch 4/500\n",
      "613/613 [==============================] - 5s 9ms/step - loss: 0.5746 - precision_16: 0.4257 - binary_accuracy: 0.7398 - val_loss: 0.5902 - val_precision_16: 0.4455 - val_binary_accuracy: 0.7324\n",
      "Epoch 5/500\n",
      "613/613 [==============================] - 5s 9ms/step - loss: 0.5737 - precision_16: 0.4549 - binary_accuracy: 0.7428 - val_loss: 0.5905 - val_precision_16: 0.3924 - val_binary_accuracy: 0.7098\n",
      "Epoch 6/500\n",
      "613/613 [==============================] - 6s 10ms/step - loss: 0.5738 - precision_16: 0.4550 - binary_accuracy: 0.7435 - val_loss: 0.5876 - val_precision_16: 0.3953 - val_binary_accuracy: 0.7138\n",
      "Epoch 7/500\n",
      "613/613 [==============================] - 5s 9ms/step - loss: 0.5731 - precision_16: 0.4365 - binary_accuracy: 0.7407 - val_loss: 0.5921 - val_precision_16: 0.3668 - val_binary_accuracy: 0.6886\n",
      "Epoch 8/500\n",
      "613/613 [==============================] - 5s 9ms/step - loss: 0.5731 - precision_16: 0.4159 - binary_accuracy: 0.7378 - val_loss: 0.5934 - val_precision_16: 0.3766 - val_binary_accuracy: 0.7117\n",
      "Epoch 9/500\n",
      "613/613 [==============================] - 6s 9ms/step - loss: 0.5731 - precision_16: 0.4386 - binary_accuracy: 0.7410 - val_loss: 0.5860 - val_precision_16: 0.4310 - val_binary_accuracy: 0.7274\n",
      "Epoch 10/500\n",
      "613/613 [==============================] - 6s 10ms/step - loss: 0.5723 - precision_16: 0.4237 - binary_accuracy: 0.7392 - val_loss: 0.5882 - val_precision_16: 0.4375 - val_binary_accuracy: 0.7324\n",
      "Epoch 11/500\n",
      "613/613 [==============================] - 6s 10ms/step - loss: 0.5728 - precision_16: 0.4269 - binary_accuracy: 0.7400 - val_loss: 0.5872 - val_precision_16: 0.4545 - val_binary_accuracy: 0.7326\n",
      "Epoch 12/500\n",
      "613/613 [==============================] - 6s 10ms/step - loss: 0.5721 - precision_16: 0.4302 - binary_accuracy: 0.7410 - val_loss: 0.5883 - val_precision_16: 0.4741 - val_binary_accuracy: 0.7338\n",
      "Epoch 13/500\n",
      "613/613 [==============================] - 6s 9ms/step - loss: 0.5716 - precision_16: 0.4440 - binary_accuracy: 0.7420 - val_loss: 0.5864 - val_precision_16: 0.4330 - val_binary_accuracy: 0.7290\n",
      "Epoch 14/500\n",
      "613/613 [==============================] - 5s 9ms/step - loss: 0.5723 - precision_16: 0.4354 - binary_accuracy: 0.7414 - val_loss: 0.5881 - val_precision_16: 0.4545 - val_binary_accuracy: 0.7312\n",
      "Epoch 15/500\n",
      "613/613 [==============================] - 5s 9ms/step - loss: 0.5722 - precision_16: 0.4465 - binary_accuracy: 0.7422 - val_loss: 0.5912 - val_precision_16: 0.4156 - val_binary_accuracy: 0.7193\n",
      "Epoch 16/500\n",
      "613/613 [==============================] - 5s 8ms/step - loss: 0.5724 - precision_16: 0.4341 - binary_accuracy: 0.7402 - val_loss: 0.5906 - val_precision_16: 0.4545 - val_binary_accuracy: 0.7343\n",
      "Epoch 17/500\n",
      "613/613 [==============================] - 5s 8ms/step - loss: 0.5726 - precision_16: 0.4423 - binary_accuracy: 0.7418 - val_loss: 0.5870 - val_precision_16: 0.5200 - val_binary_accuracy: 0.7357\n",
      "Epoch 18/500\n",
      "613/613 [==============================] - 5s 9ms/step - loss: 0.5719 - precision_16: 0.4351 - binary_accuracy: 0.7411 - val_loss: 0.5870 - val_precision_16: 0.4588 - val_binary_accuracy: 0.7336\n",
      "Epoch 19/500\n",
      "613/613 [==============================] - 6s 9ms/step - loss: 0.5713 - precision_16: 0.4309 - binary_accuracy: 0.7397 - val_loss: 0.5879 - val_precision_16: 0.5750 - val_binary_accuracy: 0.7367\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "l_history = l_model.fit(X_train, y_train,\n",
    "    batch_size=16,\n",
    "    epochs=500,\n",
    "    validation_split=0.3,\n",
    "    shuffle=True,\n",
    "    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_accuracy(l_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = l_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 1)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18666893, 0.07337698, 0.12081945, ..., 0.19522563, 0.08940387,\n",
       "       0.05261356], dtype=float32)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict[y_predict<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 3ms/step - loss: 0.5694 - precision_16: 0.4242 - binary_accuracy: 0.7395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5694441199302673, 0.42424243688583374, 0.7394999861717224]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 0.6024 batchsize 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6033 LecunUniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6038 TruncatedNormal()\n",
    "# 0.6043 initializer = tf.keras.initializers.VarianceScaling(scale=0.1, mode='fan_in', distribution='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_precision_recall_curve(history):\n",
    "    \n",
    "    fig, ax =plt.subplots(1,3,figsize=(20,5))\n",
    "    \n",
    "    # --- LOSS\n",
    "    \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend(['Train', 'Val'], loc='upper right')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- RECALL\n",
    "\n",
    "    ax[1].plot(history.history['recall'])\n",
    "    ax[1].plot(history.history['val_recall'])\n",
    "    ax[1].set_title('Model recall', fontsize = 18)\n",
    "    ax[1].set_xlabel('Epoch', fontsize = 14)\n",
    "    ax[1].set_ylabel('Recall', fontsize = 14)\n",
    "    ax[1].legend(['Train', 'Val'], loc='lower right') \n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    \n",
    "    # --- PRECISION\n",
    "    \n",
    "    \n",
    "    ax[2].plot(history.history['precision'])\n",
    "    ax[2].plot(history.history['val_precision'])\n",
    "    ax[2].set_title('Model precision', fontsize = 18)\n",
    "    ax[2].set_xlabel('Epoch', fontsize = 14)\n",
    "    ax[2].set_ylabel('Precision', fontsize = 14)\n",
    "    ax[2].legend(['Train', 'Val'], loc='lower right')  \n",
    "    ax[2].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[2].grid(axis=\"y\",linewidth=0.5)    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "import tensorflow as tf\n",
    "l_model = Sequential()\n",
    "l_model.add(layers.Masking())\n",
    "initializer = tf.keras.initializers.VarianceScaling(scale=0.1, mode='fan_in', distribution='uniform')\n",
    "l_model.add(layers.LSTM(32, activation = \"tanh\",kernel_initializer=initializer, kernel_regularizer='l2'))\n",
    "l_model.add(layers.Dense(20, activation = \"relu\"))\n",
    "l_model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "# compile\n",
    "l_model.compile(loss='binary_crossentropy',\n",
    "              optimizer= 'rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "l_history = l_model.fit(X_train, y_train,\n",
    "    batch_size=8,\n",
    "    epochs=1000,\n",
    "    validation_split=0.3,\n",
    "    shuffle=True,\n",
    "    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    \n",
    "    # --- LOSS --- \n",
    "    \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "#     ax[0].set_ylim((0,3))\n",
    "    ax[0].legend(['Train', 'Test'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- ACCURACY\n",
    "    \n",
    "    ax[1].plot(history.history['binary_accuracy'])\n",
    "    ax[1].plot(history.history['val_binary_accuracy'])\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Test'], loc='best')\n",
    "    ax[1].set_ylim((0,1))\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 40\n",
    "model = Word2Vec(sentences=data['lemmatize'], vector_size=vec_size, min_count=10, window=4)\n",
    "model.save(\"../models/w2v_150k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Word2Vec.load(\"../models/w2v_150k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x18b7e4a60>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('animal', 0.6996986865997314),\n",
       " ('pup', 0.6816320419311523),\n",
       " ('kid', 0.6189768314361572),\n",
       " ('theyre', 0.6126769185066223),\n",
       " ('mine', 0.611507773399353),\n",
       " ('pooch', 0.6083589196205139),\n",
       " ('doggos', 0.6054732203483582),\n",
       " ('doggy', 0.604890763759613),\n",
       " ('also', 0.5998243093490601),\n",
       " ('story', 0.5967597961425781),\n",
       " ('comment', 0.5960269570350647),\n",
       " ('people', 0.5943179130554199),\n",
       " ('cat', 0.5779100060462952),\n",
       " ('owner', 0.5767818093299866),\n",
       " ('mother', 0.5735674500465393)]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.wv.most_similar('dog', topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of upvotemodel.prenlp.preprocess_text failed: Traceback (most recent call last):\n",
      "  File \"/Users/wanghin/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/wanghin/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/wanghin/.pyenv/versions/3.8.12/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/wanghin/.pyenv/versions/3.8.12/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/wanghin/code/LeonNeubeck/Upvote_Model/upvotemodel/prenlp/preprocess_text.py\", line 7, in <module>\n",
      "    from UPVOTE_MODEL.upvotemodel.prenlp.contractions import CONTRACTION_MAP\n",
      "ModuleNotFoundError: No module named 'UPVOTE_MODEL'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from upvotemodel.prenlp.preprocess_text import embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "# __file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/wanghin/code/LeonNeubeck/Upvote_Model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.path.abspath(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/wanghin/code/LeonNeubeck'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.path.dirname(os.path.abspath('')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/wanghin/code/LeonNeubeck/Upvote_Model/notebooks',\n",
       " '/Users/wanghin/code/CitizenKylin/data-context-and-setup',\n",
       " '/Users/wanghin/code/LeonNeubeck/Upvote_Model/notebooks',\n",
       " '/Users/wanghin/.pyenv/versions/3.8.12/lib/python38.zip',\n",
       " '/Users/wanghin/.pyenv/versions/3.8.12/lib/python3.8',\n",
       " '/Users/wanghin/.pyenv/versions/3.8.12/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/Users/wanghin/.pyenv/versions/lewagon/lib/python3.8/site-packages',\n",
       " '/Users/wanghin/.pyenv/versions/lewagon/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/Users/wanghin/.ipython',\n",
       " '/Users/wanghin/code/LeonNeubeck/Upvote_Model']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35266894, -0.44480756,  1.2790529 ,  0.2264111 ,  0.80346364,\n",
       "         0.24137893,  0.22789069,  0.90425175, -0.08094738, -1.4144479 ,\n",
       "         1.246112  ,  1.0234498 ,  0.03637016,  0.73463815, -0.05412924,\n",
       "        -0.17712502,  1.2520365 ,  0.5288012 , -0.55155796, -1.4010589 ,\n",
       "         1.0026082 ,  0.24980044,  0.76055455,  0.04039042, -0.6380358 ,\n",
       "        -1.3701535 , -0.12179693,  1.5690833 ,  0.43725434,  0.63406813,\n",
       "        -0.50388044,  0.06886046,  1.2432551 ,  1.2660683 , -0.3588837 ,\n",
       "        -0.8647348 ,  0.63890016, -1.0180691 ,  0.23994292,  0.1479732 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(['dog'],'../models/w2v_150k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/wanghin/code/LeonNeubeck/Upvote_Model/notebooks'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fff758d5c56eda6bf3ef34f0d4cde3312389935bcf4c692bace467005533ff3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
